{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1309bdf-56c4-4ba2-95c3-e2264ca2efda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "DATA CLEANING PIPELINE - REER â†’ PROPERTY SPILLOVERS (NO OTC)\n",
      "====================================================================================================\n",
      "\n",
      "STEP 1: LOADING...\n",
      "  Loaded commercial_property: 6,538 rows\n",
      "  Loaded residential_property: 44,109 rows\n",
      "  Loaded effective_fx: 1,181,937 rows\n",
      "\n",
      "STEP 2: PROCESSING REER...\n",
      "  REER: 6,400 obs, 64 countries\n",
      "\n",
      "STEP 3: PROCESSING RESIDENTIAL...\n",
      "  Residential: 4,379 obs, 51 countries\n",
      "\n",
      "STEP 4: PROCESSING COMMERCIAL...\n",
      "  Commercial: 1,389 obs, 20 countries\n",
      "\n",
      "STEP 5: MERGING...\n",
      "  Merged panel: 6,400 obs, 64 countries\n",
      "\n",
      "STEP 6: CREATING DERIVED VARIABLES...\n",
      "  Created: log transforms, growth rates, volatility, lags\n",
      "\n",
      "STEP 7: DATA QUALITY...\n",
      "  Full balanced (REER+Residential+Commercial >90%): 4 countries\n",
      "  Residential balanced (REER+Residential >90%): 29 countries\n",
      "  Commercial balanced (REER+Commercial >90%): 6 countries\n",
      "\n",
      "STEP 8: SAVING FILES...\n",
      "  Saved: panel_full.csv (6,400 rows)\n",
      "  Saved: panel_balanced_full.csv (400 rows, 4 countries)\n",
      "    Countries: ['SG: Singapore', 'US: United States', 'XM: Euro area', 'DK: Denmark']\n",
      "  Saved: panel_balanced_residential.csv (2,900 rows, 29 countries)\n",
      "  Saved: panel_balanced_commercial.csv (600 rows, 6 countries)\n",
      "  Saved: data_completeness.csv\n",
      "  Saved: variable_descriptions.csv\n",
      "\n",
      "====================================================================================================\n",
      "DESCRIPTIVE STATISTICS\n",
      "====================================================================================================\n",
      "\n",
      "Full Panel Summary:\n",
      "       reer_broad  residential_price  commercial_price  reer_change_pct  res_price_growth  com_price_growth  reer_volatility\n",
      "count    6400.000           4379.000          1389.000         6336.000          4279.000          1353.000         6272.000\n",
      "mean      103.680           2100.491         27698.404            0.032             0.861             0.956            0.025\n",
      "std        21.340          12570.415        132596.035            3.819            13.446             5.678            0.030\n",
      "min        55.770              6.700            10.300         -117.074          -725.503           -67.509            0.001\n",
      "25%        96.178             92.900            98.800           -1.223            -0.183            -0.880            0.011\n",
      "50%       100.680            109.580           111.360            0.152             1.060             0.688            0.018\n",
      "75%       107.660            162.654           153.000            1.453             2.459             2.381            0.030\n",
      "max       509.720         152700.000        967300.000           63.634           199.606            58.032            0.768\n",
      "\n",
      "====================================================================================================\n",
      "âœ… CLEANING COMPLETE!\n",
      "====================================================================================================\n",
      "Panel: 6,400 obs | 64 countries | 2000-Q1 to 2024-Q4\n",
      "\n",
      "Balanced panels created:\n",
      "  - Full (REER+Res+Com): 4 countries\n",
      "  - Residential focus: 29 countries\n",
      "  - Commercial focus: 6 countries\n",
      "\n",
      "All files saved to: C:\\Users\\dirir\\OneDrive\\ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—\\Semester 1\\houses\\house\\workingfile\\\\\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "DATA_PATH = r\"C:\\Users\\dirir\\OneDrive\\ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—\\Semester 1\\houses\\house\\\\\"\n",
    "OUTPUT_PATH = r\"C:\\Users\\dirir\\OneDrive\\ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—\\Semester 1\\houses\\house\\workingfile\\\\\"\n",
    "\n",
    "files = {\n",
    "    'commercial_property': DATA_PATH + \"Commercial property prices (CSV, flat).csv\",\n",
    "    'residential_property': DATA_PATH + \"Detailed residential property prices (CSV, flat).csv\",\n",
    "    'effective_fx': DATA_PATH + \"Effective exchange rates (CSV, flat).csv\"\n",
    "}\n",
    "\n",
    "print(\"=\"*100)\n",
    "print(\"DATA CLEANING PIPELINE - REER â†’ PROPERTY SPILLOVERS (NO OTC)\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# STEP 1: LOAD\n",
    "print(\"\\nSTEP 1: LOADING...\")\n",
    "datasets = {}\n",
    "for name, path in files.items():\n",
    "    df = pd.read_csv(path, encoding='utf-8', low_memory=False)\n",
    "    datasets[name] = df\n",
    "    print(f\"  Loaded {name}: {len(df):,} rows\")\n",
    "\n",
    "# STEP 2: REER (Real Effective Exchange Rate)\n",
    "print(\"\\nSTEP 2: PROCESSING REER...\")\n",
    "reer = datasets['effective_fx'].copy()\n",
    "reer = reer[(reer['EER_TYPE:Type'] == 'R: Real') & \n",
    "            (reer['EER_BASKET:Basket'] == 'B: Broad (64 economies)') & \n",
    "            (reer['FREQ:Frequency'] == 'M: Monthly')].copy()\n",
    "reer = reer[reer['TIME_PERIOD:Time period or range'].notna()].copy()\n",
    "reer['year'] = reer['TIME_PERIOD:Time period or range'].str[:4].astype(int)\n",
    "reer['month'] = reer['TIME_PERIOD:Time period or range'].str[5:7].astype(int)\n",
    "reer = reer[(reer['year'] >= 2000) & (reer['year'] <= 2024)].copy()\n",
    "reer['quarter'] = ((reer['month'] - 1) // 3) + 1\n",
    "reer_quarterly = reer[reer['month'].isin([3, 6, 9, 12])].copy()\n",
    "reer_quarterly['time_period'] = reer_quarterly['year'].astype(str) + '-Q' + reer_quarterly['quarter'].astype(str)\n",
    "reer_clean = reer_quarterly[['REF_AREA:Reference area', 'time_period', 'OBS_VALUE:Observation Value']].copy()\n",
    "reer_clean.columns = ['country_code', 'time_period', 'reer_broad']\n",
    "reer_clean = reer_clean.dropna(subset=['reer_broad'])\n",
    "print(f\"  REER: {len(reer_clean):,} obs, {reer_clean['country_code'].nunique()} countries\")\n",
    "\n",
    "# STEP 3: RESIDENTIAL PROPERTY\n",
    "print(\"\\nSTEP 3: PROCESSING RESIDENTIAL...\")\n",
    "res_prop = datasets['residential_property'].copy()\n",
    "res_prop = res_prop[res_prop['FREQ:Frequency'].str.contains('Q: Quarterly', na=False)].copy()\n",
    "res_prop = res_prop[res_prop['TIME_PERIOD:Time period or range'].notna()].copy()\n",
    "res_prop = res_prop[res_prop['TIME_PERIOD:Time period or range'].str.match(r'\\d{4}-Q[1-4]', na=False)].copy()\n",
    "res_prop['year'] = res_prop['TIME_PERIOD:Time period or range'].str[:4].astype(int)\n",
    "res_prop = res_prop[(res_prop['year'] >= 2000) & (res_prop['year'] <= 2024)].copy()\n",
    "\n",
    "def calc_priority_res(row):\n",
    "    score = 0\n",
    "    if pd.notna(row.get('COVERED_AREA:Covered area')) and '0: Whole country' in str(row['COVERED_AREA:Covered area']):\n",
    "        score += 100\n",
    "    if pd.notna(row.get('RE_TYPE:Real estate type')) and '1: All types' in str(row['RE_TYPE:Real estate type']):\n",
    "        score += 50\n",
    "    if pd.notna(row.get('RE_VINTAGE:Real estate vintage')) and '0: All' in str(row['RE_VINTAGE:Real estate vintage']):\n",
    "        score += 25\n",
    "    return score\n",
    "\n",
    "res_prop['priority'] = res_prop.apply(calc_priority_res, axis=1)\n",
    "res_prop = res_prop.sort_values(['REF_AREA:Reference area', 'TIME_PERIOD:Time period or range', 'priority'], ascending=[True, True, False])\n",
    "res_prop_clean = res_prop.groupby(['REF_AREA:Reference area', 'TIME_PERIOD:Time period or range']).first().reset_index()\n",
    "res_prop_clean = res_prop_clean[['REF_AREA:Reference area', 'TIME_PERIOD:Time period or range', 'OBS_VALUE:Observation Value']].copy()\n",
    "res_prop_clean.columns = ['country_code', 'time_period', 'residential_price']\n",
    "res_prop_clean = res_prop_clean.dropna(subset=['residential_price'])\n",
    "print(f\"  Residential: {len(res_prop_clean):,} obs, {res_prop_clean['country_code'].nunique()} countries\")\n",
    "\n",
    "# STEP 4: COMMERCIAL PROPERTY\n",
    "print(\"\\nSTEP 4: PROCESSING COMMERCIAL...\")\n",
    "com_prop = datasets['commercial_property'].copy()\n",
    "com_prop = com_prop[com_prop['FREQ:Frequency'].str.contains('Q: Quarterly', na=False)].copy()\n",
    "com_prop = com_prop[com_prop['TIME_PERIOD:Time period or range'].notna()].copy()\n",
    "com_prop = com_prop[com_prop['TIME_PERIOD:Time period or range'].str.match(r'\\d{4}-Q[1-4]', na=False)].copy()\n",
    "com_prop['year'] = com_prop['TIME_PERIOD:Time period or range'].str[:4].astype(int)\n",
    "com_prop = com_prop[(com_prop['year'] >= 2000) & (com_prop['year'] <= 2024)].copy()\n",
    "\n",
    "def calc_priority_com(row):\n",
    "    score = 0\n",
    "    if pd.notna(row.get('COVERED_AREA:Covered area')) and '0: Whole country' in str(row['COVERED_AREA:Covered area']):\n",
    "        score += 100\n",
    "    if pd.notna(row.get('RE_TYPE:Real estate type')) and 'A: Commercial property' in str(row['RE_TYPE:Real estate type']):\n",
    "        score += 50\n",
    "    return score\n",
    "\n",
    "com_prop['priority'] = com_prop.apply(calc_priority_com, axis=1)\n",
    "com_prop = com_prop.sort_values(['REF_AREA:Reference area', 'TIME_PERIOD:Time period or range', 'priority'], ascending=[True, True, False])\n",
    "com_prop_clean = com_prop.groupby(['REF_AREA:Reference area', 'TIME_PERIOD:Time period or range']).first().reset_index()\n",
    "com_prop_clean = com_prop_clean[['REF_AREA:Reference area', 'TIME_PERIOD:Time period or range', 'OBS_VALUE:Observation Value']].copy()\n",
    "com_prop_clean.columns = ['country_code', 'time_period', 'commercial_price']\n",
    "com_prop_clean = com_prop_clean.dropna(subset=['commercial_price'])\n",
    "print(f\"  Commercial: {len(com_prop_clean):,} obs, {com_prop_clean['country_code'].nunique()} countries\")\n",
    "\n",
    "# STEP 5: MERGE\n",
    "print(\"\\nSTEP 5: MERGING...\")\n",
    "panel = reer_clean.copy()\n",
    "panel = panel.merge(res_prop_clean, on=['country_code', 'time_period'], how='left')\n",
    "panel = panel.merge(com_prop_clean, on=['country_code', 'time_period'], how='left')\n",
    "panel['year'] = panel['time_period'].str[:4].astype(int)\n",
    "panel['quarter'] = panel['time_period'].str[-1].astype(int)\n",
    "print(f\"  Merged panel: {len(panel):,} obs, {panel['country_code'].nunique()} countries\")\n",
    "\n",
    "# STEP 6: CREATE DERIVED VARIABLES\n",
    "print(\"\\nSTEP 6: CREATING DERIVED VARIABLES...\")\n",
    "panel = panel.sort_values(['country_code', 'year', 'quarter'])\n",
    "\n",
    "def create_variables(group):\n",
    "    # Log transformations\n",
    "    group['log_reer'] = np.log(group['reer_broad'])\n",
    "    group['log_res_price'] = np.log(group['residential_price'])\n",
    "    group['log_com_price'] = np.log(group['commercial_price'])\n",
    "    \n",
    "    # First differences (growth rates)\n",
    "    group['d_log_reer'] = group['log_reer'].diff()\n",
    "    group['d_log_res_price'] = group['log_res_price'].diff()\n",
    "    group['d_log_com_price'] = group['log_com_price'].diff()\n",
    "    \n",
    "    # Growth rates in percentage\n",
    "    group['reer_change_pct'] = group['d_log_reer'] * 100\n",
    "    group['res_price_growth'] = group['d_log_res_price'] * 100\n",
    "    group['com_price_growth'] = group['d_log_com_price'] * 100\n",
    "    \n",
    "    # REER volatility (4-quarter rolling std)\n",
    "    group['reer_volatility'] = group['d_log_reer'].rolling(window=4, min_periods=2).std()\n",
    "    \n",
    "    # REER appreciation dummy (1 if REER increased)\n",
    "    group['reer_appreciation'] = (group['d_log_reer'] > 0).astype(int)\n",
    "    \n",
    "    # Lagged variables (for models)\n",
    "    group['reer_lag1'] = group['reer_broad'].shift(1)\n",
    "    group['res_price_lag1'] = group['residential_price'].shift(1)\n",
    "    group['com_price_lag1'] = group['commercial_price'].shift(1)\n",
    "    \n",
    "    return group\n",
    "\n",
    "panel = panel.groupby('country_code', group_keys=False).apply(create_variables)\n",
    "print(f\"  Created: log transforms, growth rates, volatility, lags\")\n",
    "\n",
    "# STEP 7: DATA QUALITY ASSESSMENT\n",
    "print(\"\\nSTEP 7: DATA QUALITY...\")\n",
    "completeness = panel.groupby('country_code').agg({\n",
    "    'reer_broad': lambda x: x.notna().sum() / len(x) * 100,\n",
    "    'residential_price': lambda x: x.notna().sum() / len(x) * 100,\n",
    "    'commercial_price': lambda x: x.notna().sum() / len(x) * 100,\n",
    "    'time_period': 'count'\n",
    "}).round(2)\n",
    "completeness.columns = ['REER_%', 'Residential_%', 'Commercial_%', 'N_obs']\n",
    "completeness = completeness.sort_values('N_obs', ascending=False)\n",
    "\n",
    "# Balanced panels with different criteria\n",
    "balanced_full = completeness[(completeness['REER_%'] >= 90) & \n",
    "                             (completeness['Residential_%'] >= 90) & \n",
    "                             (completeness['Commercial_%'] >= 90)].index.tolist()\n",
    "\n",
    "balanced_res_only = completeness[(completeness['REER_%'] >= 90) & \n",
    "                                 (completeness['Residential_%'] >= 90)].index.tolist()\n",
    "\n",
    "balanced_com_only = completeness[(completeness['REER_%'] >= 90) & \n",
    "                                 (completeness['Commercial_%'] >= 90)].index.tolist()\n",
    "\n",
    "print(f\"  Full balanced (REER+Residential+Commercial >90%): {len(balanced_full)} countries\")\n",
    "print(f\"  Residential balanced (REER+Residential >90%): {len(balanced_res_only)} countries\")\n",
    "print(f\"  Commercial balanced (REER+Commercial >90%): {len(balanced_com_only)} countries\")\n",
    "\n",
    "# STEP 8: SAVE FILES\n",
    "print(\"\\nSTEP 8: SAVING FILES...\")\n",
    "panel.to_csv(OUTPUT_PATH + 'panel_full.csv', index=False)\n",
    "print(f\"  Saved: panel_full.csv ({len(panel):,} rows)\")\n",
    "\n",
    "if balanced_full:\n",
    "    panel_full_bal = panel[panel['country_code'].isin(balanced_full)].copy()\n",
    "    panel_full_bal.to_csv(OUTPUT_PATH + 'panel_balanced_full.csv', index=False)\n",
    "    print(f\"  Saved: panel_balanced_full.csv ({len(panel_full_bal):,} rows, {len(balanced_full)} countries)\")\n",
    "    print(f\"    Countries: {balanced_full}\")\n",
    "\n",
    "if balanced_res_only:\n",
    "    panel_res = panel[panel['country_code'].isin(balanced_res_only)].copy()\n",
    "    panel_res.to_csv(OUTPUT_PATH + 'panel_balanced_residential.csv', index=False)\n",
    "    print(f\"  Saved: panel_balanced_residential.csv ({len(panel_res):,} rows, {len(balanced_res_only)} countries)\")\n",
    "\n",
    "if balanced_com_only:\n",
    "    panel_com = panel[panel['country_code'].isin(balanced_com_only)].copy()\n",
    "    panel_com.to_csv(OUTPUT_PATH + 'panel_balanced_commercial.csv', index=False)\n",
    "    print(f\"  Saved: panel_balanced_commercial.csv ({len(panel_com):,} rows, {len(balanced_com_only)} countries)\")\n",
    "\n",
    "completeness.to_csv(OUTPUT_PATH + 'data_completeness.csv')\n",
    "print(f\"  Saved: data_completeness.csv\")\n",
    "\n",
    "# Variable descriptions\n",
    "var_desc = pd.DataFrame({\n",
    "    'Variable': ['country_code', 'time_period', 'year', 'quarter', \n",
    "                 'reer_broad', 'residential_price', 'commercial_price',\n",
    "                 'log_reer', 'd_log_reer', 'reer_change_pct', 'reer_volatility', 'reer_appreciation',\n",
    "                 'log_res_price', 'd_log_res_price', 'res_price_growth',\n",
    "                 'log_com_price', 'd_log_com_price', 'com_price_growth',\n",
    "                 'reer_lag1', 'res_price_lag1', 'com_price_lag1'],\n",
    "    'Description': ['ISO 2-letter country code', 'YYYY-Qn format', 'Year (numeric)', 'Quarter (1-4)',\n",
    "                    'Real Effective Exchange Rate, Broad basket (2020=100)', \n",
    "                    'Residential property price index', 'Commercial property price index',\n",
    "                    'Log of REER', 'Log difference of REER (quarterly change)', 'REER change (%)', \n",
    "                    'REER volatility (4Q rolling std)', 'Dummy: 1 if REER appreciated',\n",
    "                    'Log of residential price', 'Log difference residential', 'Residential price growth (%)',\n",
    "                    'Log of commercial price', 'Log difference commercial', 'Commercial price growth (%)',\n",
    "                    'REER lagged 1 quarter', 'Residential price lagged 1 quarter', 'Commercial price lagged 1 quarter']\n",
    "})\n",
    "var_desc.to_csv(OUTPUT_PATH + 'variable_descriptions.csv', index=False)\n",
    "print(f\"  Saved: variable_descriptions.csv\")\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"DESCRIPTIVE STATISTICS\")\n",
    "print(\"=\"*100)\n",
    "print(f\"\\nFull Panel Summary:\")\n",
    "print(panel[['reer_broad', 'residential_price', 'commercial_price', \n",
    "             'reer_change_pct', 'res_price_growth', 'com_price_growth', 'reer_volatility']].describe().round(3).to_string())\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"âœ… CLEANING COMPLETE!\")\n",
    "print(\"=\"*100)\n",
    "print(f\"Panel: {len(panel):,} obs | {panel['country_code'].nunique()} countries | {panel['time_period'].min()} to {panel['time_period'].max()}\")\n",
    "print(f\"\\nBalanced panels created:\")\n",
    "print(f\"  - Full (REER+Res+Com): {len(balanced_full)} countries\")\n",
    "print(f\"  - Residential focus: {len(balanced_res_only)} countries\")\n",
    "print(f\"  - Commercial focus: {len(balanced_com_only)} countries\")\n",
    "print(f\"\\nAll files saved to: {OUTPUT_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "42948a74-2c33-4afd-b6ad-b0b9537a95e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "ðŸŽ¨ DESCRIPTIVE STATISTICS - VIBRANT & COLORFUL\n",
      "====================================================================================================\n",
      "\n",
      "Data: 2,900 obs, 29 countries\n",
      "Period: 2000-Q1 to 2024-Q4\n",
      "\n",
      "====================================================================================================\n",
      "Creating Tables...\n",
      "====================================================================================================\n",
      "âœ“ Table1_Summary_Statistics\n",
      "âœ“ Table2_Summary_by_Group\n",
      "âœ“ Table3_Correlation_Matrix\n",
      "\n",
      "====================================================================================================\n",
      "Creating Figure 1: Distributions (Vibrant)\n",
      "====================================================================================================\n",
      "âœ“ Figure1_Distributions\n",
      "\n",
      "====================================================================================================\n",
      "Creating Figure 2: Time Series (Vibrant)\n",
      "====================================================================================================\n",
      "âœ“ Figure2_Time_Series\n",
      "\n",
      "====================================================================================================\n",
      "Creating Figure 3: Correlation Heatmap (Vibrant)\n",
      "====================================================================================================\n",
      "âœ“ Figure3_Correlation_Matrix\n",
      "\n",
      "====================================================================================================\n",
      "Creating Figure 4: Scatter Plots (Vibrant)\n",
      "====================================================================================================\n",
      "âœ“ Figure4_Scatter_REER_Property\n",
      "\n",
      "====================================================================================================\n",
      "ðŸŽ¨ DESCRIPTIVES COMPLETE - VIBRANT & COLORFUL!\n",
      "====================================================================================================\n",
      "\n",
      "ðŸ“Š TABLES (3):\n",
      "   â€¢ Table1_Summary_Statistics\n",
      "   â€¢ Table2_Summary_by_Group\n",
      "   â€¢ Table3_Correlation_Matrix\n",
      "\n",
      "ðŸŽ¨ FIGURES (4) - VIBRANT:\n",
      "   â€¢ Figure1_Distributions\n",
      "   â€¢ Figure2_Time_Series\n",
      "   â€¢ Figure3_Correlation_Matrix\n",
      "   â€¢ Figure4_Scatter_REER_Property\n",
      "\n",
      "ðŸ“ Location: C:\\Users\\dirir\\OneDrive\\ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—\\Semester 1\\houses\\house\\workingfile\\descriptives\\\\\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ============================================================================\n",
    "# VIBRANT MODERN STYLING - COLORFUL & STUNNING\n",
    "# ============================================================================\n",
    "plt.style.use('default')\n",
    "\n",
    "COLORS = {\n",
    "    'primary': '#FF6B6B',      # Vibrant red\n",
    "    'secondary': '#4ECDC4',    # Teal\n",
    "    'accent1': '#FFE66D',      # Yellow\n",
    "    'accent2': '#95E1D3',      # Mint\n",
    "    'accent3': '#F38181',      # Pink\n",
    "    'accent4': '#AA96DA',      # Purple\n",
    "    'safe_haven': '#667EEA',   # Blue-purple gradient\n",
    "    'normal': '#F093FB',       # Pink gradient\n",
    "    'bg1': '#FEF9EF',         # Warm white\n",
    "    'bg2': '#E8F5E9'          # Cool white\n",
    "}\n",
    "\n",
    "GRADIENT_SAFE = ['#667EEA', '#764BA2']  # Blue to purple\n",
    "GRADIENT_NORMAL = ['#F093FB', '#F5576C']  # Pink to red\n",
    "\n",
    "plt.rcParams.update({\n",
    "    'figure.figsize': (14, 8),\n",
    "    'font.size': 13,\n",
    "    'font.family': 'sans-serif',\n",
    "    'axes.labelsize': 15,\n",
    "    'axes.labelweight': 'bold',\n",
    "    'axes.labelcolor': '#2D3436',\n",
    "    'axes.linewidth': 2.5,\n",
    "    'axes.edgecolor': '#2D3436',\n",
    "    'axes.facecolor': 'white',\n",
    "    'figure.facecolor': 'white',\n",
    "    'grid.alpha': 0,\n",
    "    'legend.fontsize': 13,\n",
    "    'legend.frameon': False,\n",
    "    'xtick.labelsize': 12,\n",
    "    'ytick.labelsize': 12,\n",
    "    'xtick.major.width': 2,\n",
    "    'ytick.major.width': 2,\n",
    "    'xtick.color': '#2D3436',\n",
    "    'ytick.color': '#2D3436',\n",
    "    'savefig.dpi': 300,\n",
    "    'savefig.bbox': 'tight',\n",
    "    'savefig.facecolor': 'white'\n",
    "})\n",
    "\n",
    "DATA_PATH = r\"C:\\Users\\dirir\\OneDrive\\ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—\\Semester 1\\houses\\house\\workingfile\\\\\"\n",
    "OUTPUT_PATH = r\"C:\\Users\\dirir\\OneDrive\\ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—\\Semester 1\\houses\\house\\workingfile\\descriptives\\\\\"\n",
    "\n",
    "import os\n",
    "os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
    "os.makedirs(OUTPUT_PATH + 'tables', exist_ok=True)\n",
    "os.makedirs(OUTPUT_PATH + 'figures', exist_ok=True)\n",
    "\n",
    "print(\"=\"*100)\n",
    "print(\"ðŸŽ¨ DESCRIPTIVE STATISTICS - VIBRANT & COLORFUL\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# ============================================================================\n",
    "# LOAD DATA\n",
    "# ============================================================================\n",
    "df = pd.read_csv(DATA_PATH + 'panel_balanced_residential.csv')\n",
    "print(f\"\\nData: {len(df):,} obs, {df['country_code'].nunique()} countries\")\n",
    "print(f\"Period: {df['year'].min()}-Q{df['quarter'].min()} to {df['year'].max()}-Q{df['quarter'].max()}\")\n",
    "\n",
    "SAFE_HAVEN = ['US: United States', 'JP: Japan', 'CH: Switzerland', 'DE: Germany']\n",
    "df['safe_haven'] = df['country_code'].isin(SAFE_HAVEN).astype(int)\n",
    "df['country_group'] = df['safe_haven'].map({1: 'Safe Haven', 0: 'Normal'})\n",
    "\n",
    "if 'res_price_lag1' not in df.columns:\n",
    "    df = df.sort_values(['country_code', 'year', 'quarter'])\n",
    "    df['res_price_lag1'] = df.groupby('country_code')['residential_price'].shift(1)\n",
    "\n",
    "# ============================================================================\n",
    "# TABLES (SAME AS BEFORE)\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"Creating Tables...\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "vars_to_summarize = [\n",
    "    'res_price_growth', 'reer_change_pct', 'reer_volatility',\n",
    "    'reer_appreciation', 'res_price_lag1'\n",
    "]\n",
    "\n",
    "var_names = {\n",
    "    'res_price_growth': 'Property Growth (%)',\n",
    "    'reer_change_pct': 'REER Change (%)',\n",
    "    'reer_volatility': 'REER Volatility',\n",
    "    'reer_appreciation': 'REER Appreciation',\n",
    "    'res_price_lag1': 'Lagged Property Price'\n",
    "}\n",
    "\n",
    "# Table 1: Summary Stats\n",
    "summary_stats = []\n",
    "for var in vars_to_summarize:\n",
    "    data = df[var].dropna()\n",
    "    summary_stats.append({\n",
    "        'Variable': var_names[var],\n",
    "        'N': len(data),\n",
    "        'Mean': data.mean(),\n",
    "        'Std Dev': data.std(),\n",
    "        'Min': data.min(),\n",
    "        'Median': data.median(),\n",
    "        'Max': data.max()\n",
    "    })\n",
    "\n",
    "table1 = pd.DataFrame(summary_stats)\n",
    "table1.to_excel(OUTPUT_PATH + 'tables/Table1_Summary_Statistics.xlsx', index=False)\n",
    "table1.to_csv(OUTPUT_PATH + 'tables/Table1_Summary_Statistics.csv', index=False)\n",
    "print(\"âœ“ Table1_Summary_Statistics\")\n",
    "\n",
    "# Table 2: By Group\n",
    "summary_by_group = []\n",
    "for var in ['res_price_growth', 'reer_change_pct', 'reer_volatility']:\n",
    "    for group in ['Safe Haven', 'Normal']:\n",
    "        data = df[df['country_group'] == group][var].dropna()\n",
    "        summary_by_group.append({\n",
    "            'Variable': var_names[var],\n",
    "            'Group': group,\n",
    "            'N': len(data),\n",
    "            'Mean': data.mean(),\n",
    "            'Std Dev': data.std(),\n",
    "            'Median': data.median()\n",
    "        })\n",
    "\n",
    "table2 = pd.DataFrame(summary_by_group)\n",
    "table2.to_excel(OUTPUT_PATH + 'tables/Table2_Summary_by_Group.xlsx', index=False)\n",
    "table2.to_csv(OUTPUT_PATH + 'tables/Table2_Summary_by_Group.csv', index=False)\n",
    "print(\"âœ“ Table2_Summary_by_Group\")\n",
    "\n",
    "# Table 3: Correlation\n",
    "corr_vars = ['res_price_growth', 'reer_change_pct', 'reer_volatility', \n",
    "             'reer_appreciation', 'res_price_lag1']\n",
    "corr_matrix = df[corr_vars].corr()\n",
    "corr_matrix.index = [var_names[v] for v in corr_matrix.index]\n",
    "corr_matrix.columns = [var_names[v] for v in corr_matrix.columns]\n",
    "corr_matrix.to_excel(OUTPUT_PATH + 'tables/Table3_Correlation_Matrix.xlsx')\n",
    "corr_matrix.to_csv(OUTPUT_PATH + 'tables/Table3_Correlation_Matrix.csv')\n",
    "print(\"âœ“ Table3_Correlation_Matrix\")\n",
    "\n",
    "# ============================================================================\n",
    "# FIGURE 1: VIBRANT GRADIENT DISTRIBUTIONS\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"Creating Figure 1: Distributions (Vibrant)\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5.5))\n",
    "\n",
    "vars_plot = [\n",
    "    ('res_price_growth', 'Property Growth (%)'),\n",
    "    ('reer_change_pct', 'REER Change (%)'),\n",
    "    ('reer_volatility', 'REER Volatility')\n",
    "]\n",
    "\n",
    "for idx, (var, label) in enumerate(vars_plot):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    safe_data = df[df['country_group'] == 'Safe Haven'][var].dropna()\n",
    "    normal_data = df[df['country_group'] == 'Normal'][var].dropna()\n",
    "    \n",
    "    # KDE with gradient fill\n",
    "    x_safe = np.linspace(safe_data.min(), safe_data.max(), 200)\n",
    "    kde_safe = stats.gaussian_kde(safe_data)\n",
    "    y_safe = kde_safe(x_safe)\n",
    "    \n",
    "    x_normal = np.linspace(normal_data.min(), normal_data.max(), 200)\n",
    "    kde_normal = stats.gaussian_kde(normal_data)\n",
    "    y_normal = kde_normal(x_normal)\n",
    "    \n",
    "    # Fill with gradient effect\n",
    "    ax.fill_between(x_safe, 0, y_safe, alpha=0.6, color=COLORS['safe_haven'], \n",
    "                    label='Safe Haven', linewidth=0)\n",
    "    ax.plot(x_safe, y_safe, color='#4A148C', linewidth=3.5, alpha=0.9)\n",
    "    \n",
    "    ax.fill_between(x_normal, 0, y_normal, alpha=0.6, color=COLORS['normal'], \n",
    "                    label='Normal', linewidth=0)\n",
    "    ax.plot(x_normal, y_normal, color='#B71C1C', linewidth=3.5, alpha=0.9)\n",
    "    \n",
    "    ax.axvline(0, color='#2D3436', linewidth=2, alpha=0.3, linestyle='--')\n",
    "    ax.set_xlabel(label, fontsize=14, fontweight='bold')\n",
    "    ax.set_ylabel('Density', fontsize=14, fontweight='bold')\n",
    "    ax.legend(loc='upper right', fontsize=12)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.set_ylim(bottom=0)\n",
    "    \n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_linewidth(2.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_PATH + 'figures/Figure1_Distributions.png', dpi=300, bbox_inches='tight')\n",
    "plt.savefig(OUTPUT_PATH + 'figures/Figure1_Distributions.pdf', bbox_inches='tight')\n",
    "plt.close()\n",
    "print(\"âœ“ Figure1_Distributions\")\n",
    "\n",
    "# ============================================================================\n",
    "# FIGURE 2: VIBRANT TIME SERIES WITH SHADED AREAS\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"Creating Figure 2: Time Series (Vibrant)\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "df['date_numeric'] = df['year'] + (df['quarter'] - 1) / 4\n",
    "\n",
    "ts_data = df.groupby(['date_numeric', 'country_group']).agg({\n",
    "    'res_price_growth': 'mean',\n",
    "    'reer_change_pct': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(16, 9))\n",
    "\n",
    "# Property Growth\n",
    "ax = axes[0]\n",
    "for group, color, thick_color in [('Safe Haven', COLORS['safe_haven'], '#4A148C'), \n",
    "                                   ('Normal', COLORS['normal'], '#B71C1C')]:\n",
    "    data = ts_data[ts_data['country_group'] == group]\n",
    "    ax.plot(data['date_numeric'], data['res_price_growth'], \n",
    "           linewidth=3.5, alpha=0.95, color=thick_color, label=group)\n",
    "    ax.fill_between(data['date_numeric'], 0, data['res_price_growth'], \n",
    "                    alpha=0.25, color=color)\n",
    "\n",
    "ax.axhline(0, color='#2D3436', linewidth=2, alpha=0.4, linestyle='--')\n",
    "ax.axvspan(2008, 2009, alpha=0.15, color='#FFE66D', label='2008 Crisis')\n",
    "ax.axvspan(2020, 2020.5, alpha=0.15, color='#FF6B6B', label='COVID-19')\n",
    "ax.set_xlabel('Year', fontsize=15, fontweight='bold')\n",
    "ax.set_ylabel('Property Growth (%)', fontsize=15, fontweight='bold')\n",
    "ax.legend(loc='best', fontsize=12, ncol=2)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_linewidth(2.5)\n",
    "\n",
    "# REER Change\n",
    "ax = axes[1]\n",
    "for group, color, thick_color in [('Safe Haven', COLORS['safe_haven'], '#4A148C'), \n",
    "                                   ('Normal', COLORS['normal'], '#B71C1C')]:\n",
    "    data = ts_data[ts_data['country_group'] == group]\n",
    "    ax.plot(data['date_numeric'], data['reer_change_pct'], \n",
    "           linewidth=3.5, alpha=0.95, color=thick_color, label=group)\n",
    "    ax.fill_between(data['date_numeric'], 0, data['reer_change_pct'], \n",
    "                    alpha=0.25, color=color)\n",
    "\n",
    "ax.axhline(0, color='#2D3436', linewidth=2, alpha=0.4, linestyle='--')\n",
    "ax.axvspan(2008, 2009, alpha=0.15, color='#FFE66D')\n",
    "ax.axvspan(2020, 2020.5, alpha=0.15, color='#FF6B6B')\n",
    "ax.set_xlabel('Year', fontsize=15, fontweight='bold')\n",
    "ax.set_ylabel('REER Change (%)', fontsize=15, fontweight='bold')\n",
    "ax.legend(loc='best', fontsize=12)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_linewidth(2.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_PATH + 'figures/Figure2_Time_Series.png', dpi=300, bbox_inches='tight')\n",
    "plt.savefig(OUTPUT_PATH + 'figures/Figure2_Time_Series.pdf', bbox_inches='tight')\n",
    "plt.close()\n",
    "print(\"âœ“ Figure2_Time_Series\")\n",
    "\n",
    "# ============================================================================\n",
    "# FIGURE 3: VIBRANT CORRELATION HEATMAP\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"Creating Figure 3: Correlation Heatmap (Vibrant)\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "corr_data = df[corr_vars].corr()\n",
    "mask = np.triu(np.ones_like(corr_data, dtype=bool), k=1)\n",
    "\n",
    "# Custom colormap - vibrant\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "colors_cmap = ['#667EEA', '#FFFFFF', '#F5576C']\n",
    "n_bins = 100\n",
    "cmap = LinearSegmentedColormap.from_list('custom', colors_cmap, N=n_bins)\n",
    "\n",
    "sns.heatmap(corr_data, mask=mask, annot=True, fmt='.2f', \n",
    "           cmap=cmap, center=0, vmin=-0.6, vmax=0.6,\n",
    "           square=True, linewidths=3, linecolor='white',\n",
    "           cbar_kws={\"shrink\": 0.75, \"aspect\": 25},\n",
    "           annot_kws={'fontsize': 13, 'fontweight': 'bold', 'color': '#2D3436'},\n",
    "           ax=ax)\n",
    "\n",
    "labels = [var_names[v].replace(' (%)', '').replace('Property ', 'Prop. ') for v in corr_vars]\n",
    "ax.set_xticklabels(labels, rotation=45, ha='right', fontsize=13, fontweight='bold')\n",
    "ax.set_yticklabels(labels, rotation=0, fontsize=13, fontweight='bold')\n",
    "\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_linewidth(3)\n",
    "    spine.set_edgecolor('#2D3436')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_PATH + 'figures/Figure3_Correlation_Matrix.png', dpi=300, bbox_inches='tight')\n",
    "plt.savefig(OUTPUT_PATH + 'figures/Figure3_Correlation_Matrix.pdf', bbox_inches='tight')\n",
    "plt.close()\n",
    "print(\"âœ“ Figure3_Correlation_Matrix\")\n",
    "\n",
    "# ============================================================================\n",
    "# FIGURE 4: VIBRANT SCATTER WITH REGRESSION\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"Creating Figure 4: Scatter Plots (Vibrant)\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 7))\n",
    "\n",
    "# Safe Haven\n",
    "ax = axes[0]\n",
    "safe_data = df[df['country_group'] == 'Safe Haven'].dropna(subset=['reer_change_pct', 'res_price_growth'])\n",
    "\n",
    "ax.scatter(safe_data['reer_change_pct'], safe_data['res_price_growth'], \n",
    "          alpha=0.5, s=80, color=COLORS['safe_haven'], edgecolors='#4A148C', linewidth=1.5)\n",
    "\n",
    "z = np.polyfit(safe_data['reer_change_pct'], safe_data['res_price_growth'], 1)\n",
    "p = np.poly1d(z)\n",
    "x_line = np.linspace(safe_data['reer_change_pct'].min(), safe_data['reer_change_pct'].max(), 100)\n",
    "ax.plot(x_line, p(x_line), color='#FFE66D', linewidth=4.5, alpha=0.95, linestyle='-')\n",
    "\n",
    "ax.axhline(0, color='#2D3436', linewidth=2, alpha=0.3, linestyle='--')\n",
    "ax.axvline(0, color='#2D3436', linewidth=2, alpha=0.3, linestyle='--')\n",
    "ax.set_xlabel('REER Change (%)', fontsize=15, fontweight='bold')\n",
    "ax.set_ylabel('Property Growth (%)', fontsize=15, fontweight='bold')\n",
    "ax.text(0.05, 0.95, 'Safe Haven', transform=ax.transAxes, \n",
    "       fontsize=16, fontweight='bold', va='top', color='#4A148C')\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_linewidth(2.5)\n",
    "\n",
    "# Normal\n",
    "ax = axes[1]\n",
    "normal_data = df[df['country_group'] == 'Normal'].dropna(subset=['reer_change_pct', 'res_price_growth'])\n",
    "\n",
    "ax.scatter(normal_data['reer_change_pct'], normal_data['res_price_growth'], \n",
    "          alpha=0.5, s=80, color=COLORS['normal'], edgecolors='#B71C1C', linewidth=1.5)\n",
    "\n",
    "z = np.polyfit(normal_data['reer_change_pct'], normal_data['res_price_growth'], 1)\n",
    "p = np.poly1d(z)\n",
    "x_line = np.linspace(normal_data['reer_change_pct'].min(), normal_data['reer_change_pct'].max(), 100)\n",
    "ax.plot(x_line, p(x_line), color='#4ECDC4', linewidth=4.5, alpha=0.95, linestyle='-')\n",
    "\n",
    "ax.axhline(0, color='#2D3436', linewidth=2, alpha=0.3, linestyle='--')\n",
    "ax.axvline(0, color='#2D3436', linewidth=2, alpha=0.3, linestyle='--')\n",
    "ax.set_xlabel('REER Change (%)', fontsize=15, fontweight='bold')\n",
    "ax.set_ylabel('Property Growth (%)', fontsize=15, fontweight='bold')\n",
    "ax.text(0.05, 0.95, 'Normal', transform=ax.transAxes, \n",
    "       fontsize=16, fontweight='bold', va='top', color='#B71C1C')\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_linewidth(2.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_PATH + 'figures/Figure4_Scatter_REER_Property.png', dpi=300, bbox_inches='tight')\n",
    "plt.savefig(OUTPUT_PATH + 'figures/Figure4_Scatter_REER_Property.pdf', bbox_inches='tight')\n",
    "plt.close()\n",
    "print(\"âœ“ Figure4_Scatter_REER_Property\")\n",
    "\n",
    "# ============================================================================\n",
    "# SUMMARY\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"ðŸŽ¨ DESCRIPTIVES COMPLETE - VIBRANT & COLORFUL!\")\n",
    "print(\"=\"*100)\n",
    "print(\"\\nðŸ“Š TABLES (3):\")\n",
    "print(\"   â€¢ Table1_Summary_Statistics\")\n",
    "print(\"   â€¢ Table2_Summary_by_Group\")\n",
    "print(\"   â€¢ Table3_Correlation_Matrix\")\n",
    "print(\"\\nðŸŽ¨ FIGURES (4) - VIBRANT:\")\n",
    "print(\"   â€¢ Figure1_Distributions\")\n",
    "print(\"   â€¢ Figure2_Time_Series\")\n",
    "print(\"   â€¢ Figure3_Correlation_Matrix\")\n",
    "print(\"   â€¢ Figure4_Scatter_REER_Property\")\n",
    "print(f\"\\nðŸ“ Location: {OUTPUT_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "63ba442d-c1df-42e1-9b11-2c70d77af6ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "ðŸ”¬ PANEL DATA DIAGNOSTIC TESTS\n",
      "====================================================================================================\n",
      "\n",
      "ðŸ“Š Data: 2,900 observations, 29 countries\n",
      "ðŸ“… Period: 2000-Q1 to 2024-Q4\n",
      "\n",
      "====================================================================================================\n",
      "TEST 1: PANEL UNIT ROOT TESTS (IPS Method)\n",
      "====================================================================================================\n",
      "\n",
      "Testing: Property Growth (%)\n",
      "   Avg ADF: -5.326 (29 panels) - Stationary ***\n",
      "\n",
      "Testing: REER Change (%)\n",
      "   Avg ADF: -7.882 (29 panels) - Stationary ***\n",
      "\n",
      "Testing: REER Volatility\n",
      "   Avg ADF: -4.426 (29 panels) - Stationary ***\n",
      "\n",
      "Testing: REER Appreciation\n",
      "   Avg ADF: -8.346 (29 panels) - Stationary ***\n",
      "\n",
      "Testing: Lagged Property Price\n",
      "   Avg ADF: -1.904 (29 panels) - Non-Stationary\n",
      "\n",
      "âœ“ Table saved: Test1_Unit_Root_Tests\n",
      "\n",
      "====================================================================================================\n",
      "TEST 2: CROSS-SECTIONAL DEPENDENCE (Pesaran CD Test)\n",
      "====================================================================================================\n",
      "\n",
      "Testing: Property Growth (%)\n",
      "   CD Stat: 9.097, P-value: 0.0000 - Strong Dependence ***\n",
      "\n",
      "Testing: REER Change (%)\n",
      "   CD Stat: 32.307, P-value: 0.0000 - Strong Dependence ***\n",
      "\n",
      "Testing: REER Volatility\n",
      "   CD Stat: 52.298, P-value: 0.0000 - Strong Dependence ***\n",
      "\n",
      "Testing: REER Appreciation\n",
      "   CD Stat: 23.603, P-value: 0.0000 - Strong Dependence ***\n",
      "\n",
      "Testing: Lagged Property Price\n",
      "   CD Stat: 93.421, P-value: 0.0000 - Strong Dependence ***\n",
      "\n",
      "âœ“ Table saved: Test2_Cross_Sectional_Dependence\n",
      "\n",
      "====================================================================================================\n",
      "TEST 3: HAUSMAN TEST (Fixed Effects vs Random Effects)\n",
      "====================================================================================================\n",
      "   Clean data: 2,811 observations\n",
      "\n",
      "   Chi-Square: 35.137, P-value: 0.0000\n",
      "   Use Fixed Effects ***\n",
      "\n",
      "âœ“ Table saved: Test3_Hausman_Test\n",
      "\n",
      "====================================================================================================\n",
      "TEST 4: HETEROSKEDASTICITY TEST (Modified Wald)\n",
      "====================================================================================================\n",
      "\n",
      "   Variance Ratio (Max/Min): 467.76\n",
      "   Strong Heteroskedasticity ***\n",
      "\n",
      "âœ“ Table saved: Test4_Heteroskedasticity_Test\n",
      "\n",
      "====================================================================================================\n",
      "TEST 5: SERIAL CORRELATION TEST (Wooldridge)\n",
      "====================================================================================================\n",
      "\n",
      "   AR(1) Coefficient: -0.4846, P-value: 0.0000\n",
      "   Strong Serial Correlation ***\n",
      "\n",
      "âœ“ Table saved: Test5_Serial_Correlation_Test\n",
      "\n",
      "====================================================================================================\n",
      "CREATING COMPREHENSIVE DIAGNOSTIC SUMMARY\n",
      "====================================================================================================\n",
      "\n",
      "âœ“ Table saved: Diagnostic_Summary_All_Tests\n",
      "\n",
      "====================================================================================================\n",
      "ðŸ”¬ DIAGNOSTIC TESTS COMPLETE!\n",
      "====================================================================================================\n",
      "\n",
      "ðŸ“Š TABLES CREATED (6):\n",
      "   â€¢ Test1_Unit_Root_Tests\n",
      "   â€¢ Test2_Cross_Sectional_Dependence\n",
      "   â€¢ Test3_Hausman_Test\n",
      "   â€¢ Test4_Heteroskedasticity_Test\n",
      "   â€¢ Test5_Serial_Correlation_Test\n",
      "   â€¢ Diagnostic_Summary_All_Tests (COMPREHENSIVE)\n",
      "\n",
      "ðŸ“ Location: C:\\Users\\dirir\\OneDrive\\ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—\\Semester 1\\houses\\house\\workingfile\\diagnostics\\\\tables/\n",
      "\n",
      "âœ… READY FOR BASELINE MODELS!\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from statsmodels.stats.diagnostic import het_white, het_breuschpagan\n",
    "from statsmodels.stats.stattools import durbin_watson\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from linearmodels.panel import PanelOLS, RandomEffects\n",
    "from linearmodels.panel.results import compare\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ============================================================================\n",
    "# PANEL DATA DIAGNOSTIC TESTS - PUBLICATION READY TABLES\n",
    "# ============================================================================\n",
    "\n",
    "DATA_PATH = r\"C:\\Users\\dirir\\OneDrive\\ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—\\Semester 1\\houses\\house\\workingfile\\\\\"\n",
    "OUTPUT_PATH = r\"C:\\Users\\dirir\\OneDrive\\ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—\\Semester 1\\houses\\house\\workingfile\\diagnostics\\\\\"\n",
    "\n",
    "import os\n",
    "os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
    "os.makedirs(OUTPUT_PATH + 'tables', exist_ok=True)\n",
    "\n",
    "print(\"=\"*100)\n",
    "print(\"ðŸ”¬ PANEL DATA DIAGNOSTIC TESTS\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# ============================================================================\n",
    "# LOAD DATA\n",
    "# ============================================================================\n",
    "df = pd.read_csv(DATA_PATH + 'panel_balanced_residential.csv')\n",
    "\n",
    "# Create safe haven variable\n",
    "SAFE_HAVEN = ['US: United States', 'JP: Japan', 'CH: Switzerland', 'DE: Germany']\n",
    "df['safe_haven'] = df['country_code'].isin(SAFE_HAVEN).astype(int)\n",
    "\n",
    "# Create lagged variable if not exists\n",
    "if 'res_price_lag1' not in df.columns:\n",
    "    df = df.sort_values(['country_code', 'year', 'quarter'])\n",
    "    df['res_price_lag1'] = df.groupby('country_code')['residential_price'].shift(1)\n",
    "\n",
    "# âœ… FIX: Create NUMERIC time index (year.quarter format)\n",
    "df['time_numeric'] = df['year'] + (df['quarter'] - 1) / 4\n",
    "\n",
    "# Set MultiIndex with NUMERIC time\n",
    "df_panel = df.set_index(['country_code', 'time_numeric'])\n",
    "\n",
    "print(f\"\\nðŸ“Š Data: {len(df):,} observations, {df['country_code'].nunique()} countries\")\n",
    "print(f\"ðŸ“… Period: {df['year'].min()}-Q{df['quarter'].min()} to {df['year'].max()}-Q{df['quarter'].max()}\")\n",
    "\n",
    "# Variables to test\n",
    "VARIABLES = ['res_price_growth', 'reer_change_pct', 'reer_volatility', \n",
    "             'reer_appreciation', 'res_price_lag1']\n",
    "\n",
    "VAR_NAMES = {\n",
    "    'res_price_growth': 'Property Growth (%)',\n",
    "    'reer_change_pct': 'REER Change (%)',\n",
    "    'reer_volatility': 'REER Volatility',\n",
    "    'reer_appreciation': 'REER Appreciation',\n",
    "    'res_price_lag1': 'Lagged Property Price'\n",
    "}\n",
    "\n",
    "# ============================================================================\n",
    "# TEST 1: PANEL UNIT ROOT TESTS (IPS METHOD - AVERAGE ADF)\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"TEST 1: PANEL UNIT ROOT TESTS (IPS Method)\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "unit_root_results = []\n",
    "\n",
    "for var in VARIABLES:\n",
    "    print(f\"\\nTesting: {VAR_NAMES[var]}\")\n",
    "    \n",
    "    # Get data by country\n",
    "    adf_stats = []\n",
    "    countries = df['country_code'].unique()\n",
    "    \n",
    "    for country in countries:\n",
    "        country_data = df[df['country_code'] == country][var].dropna()\n",
    "        \n",
    "        if len(country_data) > 10:  # Need sufficient observations\n",
    "            try:\n",
    "                adf_result = adfuller(country_data, maxlag=4, regression='ct')\n",
    "                adf_stats.append(adf_result[0])  # Test statistic\n",
    "            except:\n",
    "                continue\n",
    "    \n",
    "    # IPS: Average of ADF statistics\n",
    "    if len(adf_stats) > 0:\n",
    "        avg_adf = np.mean(adf_stats)\n",
    "        # Approximate p-value (more negative = more stationary)\n",
    "        if avg_adf < -3.0:\n",
    "            conclusion = \"Stationary ***\"\n",
    "            stationarity = \"Yes\"\n",
    "        elif avg_adf < -2.5:\n",
    "            conclusion = \"Stationary **\"\n",
    "            stationarity = \"Yes\"\n",
    "        elif avg_adf < -2.0:\n",
    "            conclusion = \"Stationary *\"\n",
    "            stationarity = \"Yes\"\n",
    "        else:\n",
    "            conclusion = \"Non-Stationary\"\n",
    "            stationarity = \"No\"\n",
    "        \n",
    "        unit_root_results.append({\n",
    "            'Variable': VAR_NAMES[var],\n",
    "            'Avg ADF Statistic': round(avg_adf, 3),\n",
    "            'N Panels': len(adf_stats),\n",
    "            'Stationary': stationarity,\n",
    "            'Conclusion': conclusion\n",
    "        })\n",
    "        \n",
    "        print(f\"   Avg ADF: {avg_adf:.3f} ({len(adf_stats)} panels) - {conclusion}\")\n",
    "\n",
    "# Save Unit Root Test Table\n",
    "unit_root_df = pd.DataFrame(unit_root_results)\n",
    "unit_root_df.to_excel(OUTPUT_PATH + 'tables/Test1_Unit_Root_Tests.xlsx', index=False)\n",
    "unit_root_df.to_csv(OUTPUT_PATH + 'tables/Test1_Unit_Root_Tests.csv', index=False)\n",
    "print(\"\\nâœ“ Table saved: Test1_Unit_Root_Tests\")\n",
    "\n",
    "# ============================================================================\n",
    "# TEST 2: CROSS-SECTIONAL DEPENDENCE (PESARAN CD TEST)\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"TEST 2: CROSS-SECTIONAL DEPENDENCE (Pesaran CD Test)\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "cd_results = []\n",
    "\n",
    "for var in VARIABLES:\n",
    "    print(f\"\\nTesting: {VAR_NAMES[var]}\")\n",
    "    \n",
    "    # âœ… FIX: Use numeric time for pivot\n",
    "    pivot_data = df.pivot(index='time_numeric', columns='country_code', values=var).dropna()\n",
    "    \n",
    "    if pivot_data.shape[1] > 1:  # Need at least 2 countries\n",
    "        # Calculate pairwise correlations\n",
    "        corr_matrix = pivot_data.corr()\n",
    "        \n",
    "        # Extract upper triangle (exclude diagonal)\n",
    "        n = corr_matrix.shape[0]\n",
    "        upper_corr = []\n",
    "        for i in range(n):\n",
    "            for j in range(i+1, n):\n",
    "                upper_corr.append(corr_matrix.iloc[i, j])\n",
    "        \n",
    "        # Pesaran CD statistic\n",
    "        T = pivot_data.shape[0]  # Time periods\n",
    "        N = pivot_data.shape[1]  # Countries\n",
    "        avg_corr = np.mean(upper_corr)\n",
    "        \n",
    "        # CD = sqrt(2T/(N(N-1))) * sum(correlations)\n",
    "        cd_stat = np.sqrt(2 * T / (N * (N - 1))) * np.sum(upper_corr)\n",
    "        \n",
    "        # P-value (CD follows N(0,1) under H0: no cross-sectional dependence)\n",
    "        p_value = 2 * (1 - stats.norm.cdf(abs(cd_stat)))\n",
    "        \n",
    "        if p_value < 0.01:\n",
    "            conclusion = \"Strong Dependence ***\"\n",
    "        elif p_value < 0.05:\n",
    "            conclusion = \"Moderate Dependence **\"\n",
    "        elif p_value < 0.10:\n",
    "            conclusion = \"Weak Dependence *\"\n",
    "        else:\n",
    "            conclusion = \"No Dependence\"\n",
    "        \n",
    "        cd_results.append({\n",
    "            'Variable': VAR_NAMES[var],\n",
    "            'CD Statistic': round(cd_stat, 3),\n",
    "            'P-value': round(p_value, 4),\n",
    "            'Avg Correlation': round(avg_corr, 3),\n",
    "            'Conclusion': conclusion\n",
    "        })\n",
    "        \n",
    "        print(f\"   CD Stat: {cd_stat:.3f}, P-value: {p_value:.4f} - {conclusion}\")\n",
    "\n",
    "# Save CD Test Table\n",
    "cd_df = pd.DataFrame(cd_results)\n",
    "cd_df.to_excel(OUTPUT_PATH + 'tables/Test2_Cross_Sectional_Dependence.xlsx', index=False)\n",
    "cd_df.to_csv(OUTPUT_PATH + 'tables/Test2_Cross_Sectional_Dependence.csv', index=False)\n",
    "print(\"\\nâœ“ Table saved: Test2_Cross_Sectional_Dependence\")\n",
    "\n",
    "# ============================================================================\n",
    "# TEST 3: HAUSMAN TEST (FE vs RE)\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"TEST 3: HAUSMAN TEST (Fixed Effects vs Random Effects)\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# Drop missing values for panel regression\n",
    "df_clean = df_panel[['res_price_growth', 'reer_change_pct', 'reer_volatility', \n",
    "                      'reer_appreciation', 'res_price_lag1']].dropna()\n",
    "\n",
    "print(f\"   Clean data: {len(df_clean):,} observations\")\n",
    "\n",
    "# Fixed Effects Model\n",
    "fe_model = PanelOLS(\n",
    "    dependent=df_clean['res_price_growth'],\n",
    "    exog=df_clean[['reer_change_pct', 'reer_volatility', 'reer_appreciation', 'res_price_lag1']],\n",
    "    entity_effects=True,\n",
    "    time_effects=True\n",
    ")\n",
    "fe_results = fe_model.fit(cov_type='clustered', cluster_entity=True)\n",
    "\n",
    "# Random Effects Model\n",
    "re_model = RandomEffects(\n",
    "    dependent=df_clean['res_price_growth'],\n",
    "    exog=df_clean[['reer_change_pct', 'reer_volatility', 'reer_appreciation', 'res_price_lag1']]\n",
    ")\n",
    "re_results = re_model.fit(cov_type='clustered', cluster_entity=True)\n",
    "\n",
    "# Hausman Test\n",
    "# H0: Random Effects is consistent and efficient\n",
    "# H1: Only Fixed Effects is consistent\n",
    "\n",
    "fe_params = fe_results.params[['reer_change_pct', 'reer_volatility', 'reer_appreciation', 'res_price_lag1']]\n",
    "re_params = re_results.params[['reer_change_pct', 'reer_volatility', 'reer_appreciation', 'res_price_lag1']]\n",
    "\n",
    "fe_cov = fe_results.cov[['reer_change_pct', 'reer_volatility', 'reer_appreciation', 'res_price_lag1']].loc[['reer_change_pct', 'reer_volatility', 'reer_appreciation', 'res_price_lag1']]\n",
    "re_cov = re_results.cov[['reer_change_pct', 'reer_volatility', 'reer_appreciation', 'res_price_lag1']].loc[['reer_change_pct', 'reer_volatility', 'reer_appreciation', 'res_price_lag1']]\n",
    "\n",
    "# Calculate Hausman statistic\n",
    "diff = fe_params - re_params\n",
    "cov_diff = fe_cov - re_cov\n",
    "\n",
    "try:\n",
    "    hausman_stat = diff.T @ np.linalg.inv(cov_diff) @ diff\n",
    "    df_hausman = len(diff)\n",
    "    hausman_pval = 1 - stats.chi2.cdf(hausman_stat, df_hausman)\n",
    "    \n",
    "    if hausman_pval < 0.01:\n",
    "        conclusion = \"Use Fixed Effects ***\"\n",
    "    elif hausman_pval < 0.05:\n",
    "        conclusion = \"Use Fixed Effects **\"\n",
    "    elif hausman_pval < 0.10:\n",
    "        conclusion = \"Use Fixed Effects *\"\n",
    "    else:\n",
    "        conclusion = \"Random Effects OK\"\n",
    "    \n",
    "    hausman_results = [{\n",
    "        'Test': 'Hausman Test',\n",
    "        'Chi-Square Statistic': round(hausman_stat, 3),\n",
    "        'Degrees of Freedom': df_hausman,\n",
    "        'P-value': round(hausman_pval, 4),\n",
    "        'Conclusion': conclusion\n",
    "    }]\n",
    "    \n",
    "    print(f\"\\n   Chi-Square: {hausman_stat:.3f}, P-value: {hausman_pval:.4f}\")\n",
    "    print(f\"   {conclusion}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n   âš  Could not compute Hausman test: {str(e)}\")\n",
    "    hausman_results = [{\n",
    "        'Test': 'Hausman Test',\n",
    "        'Chi-Square Statistic': 'NA',\n",
    "        'Degrees of Freedom': 'NA',\n",
    "        'P-value': 'NA',\n",
    "        'Conclusion': 'Could not compute (use FE by default)'\n",
    "    }]\n",
    "\n",
    "# Save Hausman Test Table\n",
    "hausman_df = pd.DataFrame(hausman_results)\n",
    "hausman_df.to_excel(OUTPUT_PATH + 'tables/Test3_Hausman_Test.xlsx', index=False)\n",
    "hausman_df.to_csv(OUTPUT_PATH + 'tables/Test3_Hausman_Test.csv', index=False)\n",
    "print(\"\\nâœ“ Table saved: Test3_Hausman_Test\")\n",
    "\n",
    "# ============================================================================\n",
    "# TEST 4: HETEROSKEDASTICITY (MODIFIED WALD TEST)\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"TEST 4: HETEROSKEDASTICITY TEST (Modified Wald)\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# Get residuals from FE model\n",
    "residuals = fe_results.resids\n",
    "\n",
    "# Group residuals by country\n",
    "resid_by_country = df_clean.reset_index().copy()\n",
    "resid_by_country['residuals'] = residuals.values\n",
    "\n",
    "# Calculate variance by country\n",
    "country_vars = resid_by_country.groupby('country_code')['residuals'].var()\n",
    "\n",
    "# Modified Wald Test for groupwise heteroskedasticity\n",
    "# H0: Homoskedasticity (equal variances)\n",
    "n_countries = len(country_vars)\n",
    "T_avg = len(residuals) / n_countries\n",
    "\n",
    "# Test statistic (simplified version)\n",
    "var_ratio = country_vars.max() / country_vars.min()\n",
    "\n",
    "if var_ratio > 10:\n",
    "    hetero_conclusion = \"Strong Heteroskedasticity ***\"\n",
    "elif var_ratio > 5:\n",
    "    hetero_conclusion = \"Moderate Heteroskedasticity **\"\n",
    "elif var_ratio > 2:\n",
    "    hetero_conclusion = \"Weak Heteroskedasticity *\"\n",
    "else:\n",
    "    hetero_conclusion = \"Homoskedasticity\"\n",
    "\n",
    "hetero_results = [{\n",
    "    'Test': 'Modified Wald Test',\n",
    "    'Max Variance': round(country_vars.max(), 4),\n",
    "    'Min Variance': round(country_vars.min(), 4),\n",
    "    'Variance Ratio': round(var_ratio, 2),\n",
    "    'Conclusion': hetero_conclusion\n",
    "}]\n",
    "\n",
    "print(f\"\\n   Variance Ratio (Max/Min): {var_ratio:.2f}\")\n",
    "print(f\"   {hetero_conclusion}\")\n",
    "\n",
    "# Save Heteroskedasticity Test Table\n",
    "hetero_df = pd.DataFrame(hetero_results)\n",
    "hetero_df.to_excel(OUTPUT_PATH + 'tables/Test4_Heteroskedasticity_Test.xlsx', index=False)\n",
    "hetero_df.to_csv(OUTPUT_PATH + 'tables/Test4_Heteroskedasticity_Test.csv', index=False)\n",
    "print(\"\\nâœ“ Table saved: Test4_Heteroskedasticity_Test\")\n",
    "\n",
    "# ============================================================================\n",
    "# TEST 5: SERIAL CORRELATION (WOOLDRIDGE TEST)\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"TEST 5: SERIAL CORRELATION TEST (Wooldridge)\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# Wooldridge test for autocorrelation in panel data\n",
    "# Based on first-differenced residuals\n",
    "\n",
    "resid_by_panel = resid_by_country.set_index(['country_code', 'time_numeric'])['residuals']\n",
    "\n",
    "# Calculate first differences by country\n",
    "resid_diff = resid_by_panel.groupby(level=0).diff()\n",
    "\n",
    "# Run regression: Î”e_t on Î”e_{t-1}\n",
    "resid_diff_lag = resid_diff.groupby(level=0).shift(1)\n",
    "\n",
    "# Combine and drop NaN\n",
    "ar_data = pd.DataFrame({\n",
    "    'resid_diff': resid_diff,\n",
    "    'resid_diff_lag': resid_diff_lag\n",
    "}).dropna()\n",
    "\n",
    "# OLS regression\n",
    "from statsmodels.api import OLS, add_constant\n",
    "X_ar = add_constant(ar_data['resid_diff_lag'])\n",
    "y_ar = ar_data['resid_diff']\n",
    "ar_model = OLS(y_ar, X_ar).fit()\n",
    "\n",
    "# Test statistic\n",
    "rho = ar_model.params['resid_diff_lag']\n",
    "t_stat = ar_model.tvalues['resid_diff_lag']\n",
    "p_value = ar_model.pvalues['resid_diff_lag']\n",
    "\n",
    "if p_value < 0.01:\n",
    "    serial_conclusion = \"Strong Serial Correlation ***\"\n",
    "elif p_value < 0.05:\n",
    "    serial_conclusion = \"Moderate Serial Correlation **\"\n",
    "elif p_value < 0.10:\n",
    "    serial_conclusion = \"Weak Serial Correlation *\"\n",
    "else:\n",
    "    serial_conclusion = \"No Serial Correlation\"\n",
    "\n",
    "serial_results = [{\n",
    "    'Test': 'Wooldridge Test',\n",
    "    'AR(1) Coefficient': round(rho, 4),\n",
    "    'T-Statistic': round(t_stat, 3),\n",
    "    'P-value': round(p_value, 4),\n",
    "    'Conclusion': serial_conclusion\n",
    "}]\n",
    "\n",
    "print(f\"\\n   AR(1) Coefficient: {rho:.4f}, P-value: {p_value:.4f}\")\n",
    "print(f\"   {serial_conclusion}\")\n",
    "\n",
    "# Save Serial Correlation Test Table\n",
    "serial_df = pd.DataFrame(serial_results)\n",
    "serial_df.to_excel(OUTPUT_PATH + 'tables/Test5_Serial_Correlation_Test.xlsx', index=False)\n",
    "serial_df.to_csv(OUTPUT_PATH + 'tables/Test5_Serial_Correlation_Test.csv', index=False)\n",
    "print(\"\\nâœ“ Table saved: Test5_Serial_Correlation_Test\")\n",
    "\n",
    "# ============================================================================\n",
    "# CREATE COMPREHENSIVE SUMMARY TABLE\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"CREATING COMPREHENSIVE DIAGNOSTIC SUMMARY\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "summary_data = {\n",
    "    'Test': [\n",
    "        '1. Unit Root (IPS)',\n",
    "        '2. Cross-Sectional Dependence',\n",
    "        '3. Hausman Test',\n",
    "        '4. Heteroskedasticity',\n",
    "        '5. Serial Correlation'\n",
    "    ],\n",
    "    'Result': [\n",
    "        f\"{sum([1 for r in unit_root_results if r['Stationary'] == 'Yes'])}/{len(unit_root_results)} variables stationary\",\n",
    "        cd_results[0]['Conclusion'] if len(cd_results) > 0 else 'NA',\n",
    "        hausman_results[0]['Conclusion'],\n",
    "        hetero_results[0]['Conclusion'],\n",
    "        serial_results[0]['Conclusion']\n",
    "    ],\n",
    "    'Implication': [\n",
    "        'Variables are stationary (safe for regression)',\n",
    "        'Robust standard errors recommended',\n",
    "        'Fixed Effects preferred over Random Effects',\n",
    "        'Use clustered/robust standard errors',\n",
    "        'Consider lagged dependent variable or AR errors'\n",
    "    ],\n",
    "    'Action': [\n",
    "        'âœ“ Proceed with current specification',\n",
    "        'âœ“ Use clustered SEs',\n",
    "        'âœ“ Use Fixed Effects model',\n",
    "        'âœ“ Apply robust covariance estimator',\n",
    "        'âœ“ Include lagged DV (already done)'\n",
    "    ]\n",
    "}\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "summary_df.to_excel(OUTPUT_PATH + 'tables/Diagnostic_Summary_All_Tests.xlsx', index=False)\n",
    "summary_df.to_csv(OUTPUT_PATH + 'tables/Diagnostic_Summary_All_Tests.csv', index=False)\n",
    "print(\"\\nâœ“ Table saved: Diagnostic_Summary_All_Tests\")\n",
    "\n",
    "# ============================================================================\n",
    "# FINAL SUMMARY\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"ðŸ”¬ DIAGNOSTIC TESTS COMPLETE!\")\n",
    "print(\"=\"*100)\n",
    "print(\"\\nðŸ“Š TABLES CREATED (6):\")\n",
    "print(\"   â€¢ Test1_Unit_Root_Tests\")\n",
    "print(\"   â€¢ Test2_Cross_Sectional_Dependence\")\n",
    "print(\"   â€¢ Test3_Hausman_Test\")\n",
    "print(\"   â€¢ Test4_Heteroskedasticity_Test\")\n",
    "print(\"   â€¢ Test5_Serial_Correlation_Test\")\n",
    "print(\"   â€¢ Diagnostic_Summary_All_Tests (COMPREHENSIVE)\")\n",
    "print(f\"\\nðŸ“ Location: {OUTPUT_PATH}tables/\")\n",
    "print(\"\\nâœ… READY FOR BASELINE MODELS!\")\n",
    "print(\"=\"*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "334067ca-b172-4c14-bd7e-90c86791ef64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "ðŸš¨ CRISIS INTERACTION MODEL - FLIGHT-TO-SAFETY CONTAGION\n",
      "====================================================================================================\n",
      "\n",
      "====================================================================================================\n",
      "ðŸš¨ DEFINING CRISIS PERIODS\n",
      "====================================================================================================\n",
      "âœ“ Crisis periods defined:\n",
      "   â€¢ 2008-2009: Global Financial Crisis\n",
      "   â€¢ 2011-2012: European Debt Crisis\n",
      "   â€¢ 2020-2021: COVID-19 Pandemic\n",
      "   â€¢ 2022: Ukraine War / Energy Crisis\n",
      "\n",
      "ðŸ“Š Crisis observations: 812 / 2,900 (28.0%)\n",
      "\n",
      "====================================================================================================\n",
      "ðŸ”§ CREATING INTERACTION TERMS\n",
      "====================================================================================================\n",
      "âœ“ Interaction terms created:\n",
      "   â€¢ reer_x_safe: REER Ã— Safe Haven\n",
      "   â€¢ reer_x_crisis: REER Ã— Crisis\n",
      "   â€¢ reer_x_safe_x_crisis: REER Ã— Safe Haven Ã— Crisis (TRIPLE)\n",
      "\n",
      "ðŸ“Š Data: 2,900 observations, 29 countries\n",
      "   â€¢ Safe Haven: 300 obs (3 countries)\n",
      "   â€¢ Normal: 2,600 obs (26 countries)\n",
      "\n",
      "====================================================================================================\n",
      "MODEL 1: Baseline (No Interaction)\n",
      "====================================================================================================\n",
      "âœ“ Model 1: REER Change = -0.0121 (p = 0.8191)\n",
      "           RÂ² = 0.0015, Within RÂ² = 0.0017\n",
      "\n",
      "====================================================================================================\n",
      "MODEL 2: Safe Haven Interaction (REER Ã— Safe Haven)\n",
      "====================================================================================================\n",
      "âœ“ Model 2: REER Change = -0.0124 (p = 0.8126)\n",
      "           REER Ã— Safe Haven = 0.0114 (p = 0.8407)\n",
      "           RÂ² = 0.0015, Within RÂ² = 0.0017\n",
      "\n",
      "====================================================================================================\n",
      "MODEL 3: Crisis Interaction (REER Ã— Crisis) - NO TIME FE\n",
      "====================================================================================================\n",
      "âœ“ Model 3: REER Change = 0.0979 (p = 0.1179)\n",
      "           REER Ã— Crisis = -0.1512 (p = 0.0064)\n",
      "           Crisis Dummy = -0.4114 (p = 0.3270)\n",
      "           RÂ² = 0.0031, Within RÂ² = 0.0031\n",
      "\n",
      "====================================================================================================\n",
      "MODEL 4: TRIPLE INTERACTION (REER Ã— Safe Ã— Crisis) - TIME FE ABSORBS CRISIS ðŸŽ¯\n",
      "====================================================================================================\n",
      "âœ“ Model 4: REER Change = 0.0731 (p = 0.2718)\n",
      "           REER Ã— Safe Haven = -0.0074 (p = 0.9037)\n",
      "           REER Ã— Crisis = -0.1513 (p = 0.0059)\n",
      "           REER Ã— Safe Ã— Crisis = 0.0312 (p = 0.7435) ðŸŽ¯\n",
      "           RÂ² = 0.0022, Within RÂ² = 0.0024\n",
      "\n",
      "====================================================================================================\n",
      "ðŸŽ¯ MAIN RESULTS (Model 4 - Triple Interaction)\n",
      "====================================================================================================\n",
      "                          PanelOLS Estimation Summary                           \n",
      "================================================================================\n",
      "Dep. Variable:       res_price_growth   R-squared:                        0.0022\n",
      "Estimator:                   PanelOLS   R-squared (Between):             -0.4049\n",
      "No. Observations:                2811   R-squared (Within):               0.0024\n",
      "Date:                Tue, Dec 09 2025   R-squared (Overall):             -0.0084\n",
      "Time:                        22:41:26   Log-likelihood                   -9911.6\n",
      "Cov. Estimator:        Driscoll-Kraay                                           \n",
      "                                        F-statistic:                      0.8416\n",
      "Entities:                          29   P-value                           0.5526\n",
      "Avg Obs:                       96.931   Distribution:                  F(7,2678)\n",
      "Min Obs:                       91.000                                           \n",
      "Max Obs:                       98.000   F-statistic (robust):             2.7728\n",
      "                                        P-value                           0.0071\n",
      "Time periods:                      98   Distribution:                  F(7,2678)\n",
      "Avg Obs:                       28.684                                           \n",
      "Min Obs:                       24.000                                           \n",
      "Max Obs:                       29.000                                           \n",
      "                                                                                \n",
      "                                  Parameter Estimates                                   \n",
      "========================================================================================\n",
      "                      Parameter  Std. Err.     T-stat    P-value    Lower CI    Upper CI\n",
      "----------------------------------------------------------------------------------------\n",
      "reer_change_pct          0.0731     0.0665     1.0991     0.2718     -0.0573      0.2036\n",
      "reer_x_safe             -0.0074     0.0611    -0.1210     0.9037     -0.1272      0.1124\n",
      "reer_x_crisis           -0.1513     0.0549    -2.7567     0.0059     -0.2589     -0.0437\n",
      "reer_x_safe_x_crisis     0.0312     0.0953     0.3273     0.7435     -0.1557      0.2181\n",
      "reer_volatility          5.8140     5.1235     1.1348     0.2566     -4.2324      15.860\n",
      "reer_appreciation        0.0539     0.5051     0.1068     0.9150     -0.9364      1.0443\n",
      "res_price_lag1       -7.299e-05  3.149e-05    -2.3180     0.0205     -0.0001  -1.125e-05\n",
      "========================================================================================\n",
      "\n",
      "F-test for Poolability: 0.7709\n",
      "P-value: 0.9709\n",
      "Distribution: F(125,2678)\n",
      "\n",
      "Included effects: Entity, Time\n",
      "\n",
      "====================================================================================================\n",
      "ðŸ“Š MARGINAL EFFECTS (Effect of 1% REER Appreciation)\n",
      "====================================================================================================\n",
      "\n",
      "1. Normal Countries, Normal Times:\n",
      "   Effect: 0.0731\n",
      "\n",
      "2. Safe Haven Countries, Normal Times:\n",
      "   Effect: 0.0657\n",
      "   Difference from (1): -0.0074\n",
      "\n",
      "3. Normal Countries, Crisis Times:\n",
      "   Effect: -0.0782\n",
      "   Difference from (1): -0.1513\n",
      "\n",
      "4. Safe Haven Countries, Crisis Times: ðŸŽ¯\n",
      "   Effect: -0.0544\n",
      "   Difference from (3): 0.0238\n",
      "\n",
      "ðŸ’¡ FLIGHT-TO-SAFETY REVERSAL = 0.0238\n",
      "   (How much MORE safe havens respond vs normal countries during crises)\n",
      "\n",
      "====================================================================================================\n",
      "ðŸ“Š CREATING COMPARISON TABLE\n",
      "====================================================================================================\n",
      "âœ“ Table saved: Crisis_Interaction_Models\n",
      "\n",
      "                     Variable        Model 1        Model 2        Model 3        Model 4\n",
      "              REER Change (%)        -0.0121        -0.0124         0.0979         0.0731\n",
      "                                    (0.0528)       (0.0525)       (0.0626)       (0.0665)\n",
      "            REER Ã— Safe Haven              â€”         0.0114              â€”        -0.0074\n",
      "                                                   (0.0567)                      (0.0611)\n",
      "                REER Ã— Crisis              â€”              â€”     -0.1512***     -0.1513***\n",
      "                                                                  (0.0554)       (0.0549)\n",
      "REER Ã— Safe Ã— Crisis (TRIPLE)              â€”              â€”              â€”         0.0312\n",
      "                                                                                 (0.0953)\n",
      "                 Crisis Dummy              â€”              â€”        -0.4114              â€”\n",
      "                                                                  (0.4196)               \n",
      "              REER Volatility         4.5228         4.5346         2.0991         5.8140\n",
      "                                    (4.7747)       (4.8005)       (4.6702)       (5.1235)\n",
      "            REER Appreciation         0.1814         0.1785        -0.0306         0.0539\n",
      "                                    (0.4817)       (0.4879)       (0.4426)       (0.5051)\n",
      "        Lagged Property Price      -0.0001**      -0.0001**      -0.0001**      -0.0001**\n",
      "                                    (0.0000)       (0.0000)       (0.0000)       (0.0000)\n",
      "                                                                                         \n",
      "        Country Fixed Effects            Yes            Yes            Yes            Yes\n",
      "           Time Fixed Effects            Yes            Yes             No            Yes\n",
      "              Standard Errors Driscoll-Kraay Driscoll-Kraay Driscoll-Kraay Driscoll-Kraay\n",
      "                                                                                         \n",
      "                 Observations          2,811          2,811          2,811          2,811\n",
      "                           RÂ²         0.0015         0.0015         0.0031         0.0022\n",
      "                    Within RÂ²         0.0017         0.0017         0.0031         0.0024\n",
      "\n",
      "âœ“ Table saved: Marginal_Effects_Scenarios\n",
      "\n",
      "====================================================================================================\n",
      "ðŸ“Š MARGINAL EFFECTS TABLE\n",
      "====================================================================================================\n",
      "                               Scenario Marginal Effect vs Normal/Normal                                   Interpretation\n",
      "      1. Normal Countries, Normal Times          0.0731                â€” Baseline effect (normal countries, normal times)\n",
      "  2. Safe Haven Countries, Normal Times          0.0657          -0.0074               Safe haven premium in normal times\n",
      "      3. Normal Countries, Crisis Times         -0.0782          -0.1513               Crisis effect for normal countries\n",
      "4. Safe Haven Countries, Crisis Times ðŸŽ¯         -0.0544          -0.1275       FLIGHT-TO-SAFETY: Safe haven during crisis\n",
      "\n",
      "====================================================================================================\n",
      "âœ… CRISIS INTERACTION MODELS COMPLETE!\n",
      "====================================================================================================\n",
      "\n",
      "ðŸ“ Location: C:\\Users\\dirir\\OneDrive\\ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—\\Semester 1\\houses\\house\\workingfile\\crisis_models\\\\tables/\n",
      "\n",
      "ðŸŽ¯ KEY FINDING (Triple Interaction):\n",
      "   Î² (REER Ã— Safe Ã— Crisis) = 0.0312\n",
      "   P-value = 0.7435\n",
      "   âŒ Not significant (yet)\n",
      "\n",
      "ðŸ’¡ INTERPRETATION:\n",
      "   â€¢ Triple interaction tests if safe haven effect REVERSES during crises\n",
      "   â€¢ Positive coefficient = flight-to-safety strengthens property prices\n",
      "   â€¢ Model 4 uses Time FE (absorbs crisis main effect, keeps interactions)\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from linearmodels.panel import PanelOLS\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ============================================================================\n",
    "# PART 1: CRISIS INTERACTION MODEL - FLIGHT-TO-SAFETY ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "DATA_PATH = r\"C:\\Users\\dirir\\OneDrive\\ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—\\Semester 1\\houses\\house\\workingfile\\\\\"\n",
    "OUTPUT_PATH = r\"C:\\Users\\dirir\\OneDrive\\ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—\\Semester 1\\houses\\house\\workingfile\\crisis_models\\\\\"\n",
    "\n",
    "import os\n",
    "os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
    "os.makedirs(OUTPUT_PATH + 'tables', exist_ok=True)\n",
    "\n",
    "print(\"=\"*100)\n",
    "print(\"ðŸš¨ CRISIS INTERACTION MODEL - FLIGHT-TO-SAFETY CONTAGION\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# ============================================================================\n",
    "# LOAD DATA\n",
    "# ============================================================================\n",
    "df = pd.read_csv(DATA_PATH + 'panel_balanced_residential.csv')\n",
    "\n",
    "# Create safe haven variable\n",
    "SAFE_HAVEN = ['US: United States', 'JP: Japan', 'CH: Switzerland', 'DE: Germany']\n",
    "df['safe_haven'] = df['country_code'].isin(SAFE_HAVEN).astype(int)\n",
    "\n",
    "# Create lagged variable if not exists\n",
    "if 'res_price_lag1' not in df.columns:\n",
    "    df = df.sort_values(['country_code', 'year', 'quarter'])\n",
    "    df['res_price_lag1'] = df.groupby('country_code')['residential_price'].shift(1)\n",
    "\n",
    "# ============================================================================\n",
    "# CREATE CRISIS DUMMY (KEY ADDITION!)\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"ðŸš¨ DEFINING CRISIS PERIODS\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "df['crisis'] = 0\n",
    "\n",
    "# Global Financial Crisis (2008-2009)\n",
    "df.loc[(df['year'] >= 2008) & (df['year'] <= 2009), 'crisis'] = 1\n",
    "\n",
    "# European Debt Crisis (2011-2012)\n",
    "df.loc[(df['year'] >= 2011) & (df['year'] <= 2012), 'crisis'] = 1\n",
    "\n",
    "# COVID-19 Pandemic (2020-2021)\n",
    "df.loc[(df['year'] >= 2020) & (df['year'] <= 2021), 'crisis'] = 1\n",
    "\n",
    "# Ukraine War / Energy Crisis (2022)\n",
    "df.loc[df['year'] == 2022, 'crisis'] = 1\n",
    "\n",
    "print(f\"âœ“ Crisis periods defined:\")\n",
    "print(f\"   â€¢ 2008-2009: Global Financial Crisis\")\n",
    "print(f\"   â€¢ 2011-2012: European Debt Crisis\")\n",
    "print(f\"   â€¢ 2020-2021: COVID-19 Pandemic\")\n",
    "print(f\"   â€¢ 2022: Ukraine War / Energy Crisis\")\n",
    "print(f\"\\nðŸ“Š Crisis observations: {df['crisis'].sum():,} / {len(df):,} ({100*df['crisis'].mean():.1f}%)\")\n",
    "\n",
    "# ============================================================================\n",
    "# CREATE INTERACTION TERMS\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"ðŸ”§ CREATING INTERACTION TERMS\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# Two-way interactions\n",
    "df['reer_x_safe'] = df['reer_change_pct'] * df['safe_haven']\n",
    "df['reer_x_crisis'] = df['reer_change_pct'] * df['crisis']\n",
    "\n",
    "# Three-way interaction (KEY VARIABLE!)\n",
    "df['reer_x_safe_x_crisis'] = df['reer_change_pct'] * df['safe_haven'] * df['crisis']\n",
    "\n",
    "print(\"âœ“ Interaction terms created:\")\n",
    "print(\"   â€¢ reer_x_safe: REER Ã— Safe Haven\")\n",
    "print(\"   â€¢ reer_x_crisis: REER Ã— Crisis\")\n",
    "print(\"   â€¢ reer_x_safe_x_crisis: REER Ã— Safe Haven Ã— Crisis (TRIPLE)\")\n",
    "\n",
    "# Create NUMERIC time index\n",
    "df['time_numeric'] = df['year'] + (df['quarter'] - 1) / 4\n",
    "\n",
    "# Set MultiIndex\n",
    "df_panel = df.set_index(['country_code', 'time_numeric'])\n",
    "\n",
    "print(f\"\\nðŸ“Š Data: {len(df):,} observations, {df['country_code'].nunique()} countries\")\n",
    "print(f\"   â€¢ Safe Haven: {df['safe_haven'].sum():,} obs ({df[df['safe_haven']==1]['country_code'].nunique()} countries)\")\n",
    "print(f\"   â€¢ Normal: {(1-df['safe_haven']).sum():,} obs ({df[df['safe_haven']==0]['country_code'].nunique()} countries)\")\n",
    "\n",
    "# ============================================================================\n",
    "# MODEL 1: BASELINE (NO INTERACTION)\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"MODEL 1: Baseline (No Interaction)\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "df_clean1 = df_panel[['res_price_growth', 'reer_change_pct', 'reer_volatility', \n",
    "                       'reer_appreciation', 'res_price_lag1']].dropna()\n",
    "\n",
    "model1 = PanelOLS(\n",
    "    dependent=df_clean1['res_price_growth'],\n",
    "    exog=df_clean1[['reer_change_pct', 'reer_volatility', 'reer_appreciation', 'res_price_lag1']],\n",
    "    entity_effects=True,\n",
    "    time_effects=True\n",
    ")\n",
    "results1 = model1.fit(cov_type='kernel', kernel='bartlett', bandwidth=4)\n",
    "\n",
    "print(f\"âœ“ Model 1: REER Change = {results1.params['reer_change_pct']:.4f} (p = {results1.pvalues['reer_change_pct']:.4f})\")\n",
    "print(f\"           RÂ² = {results1.rsquared:.4f}, Within RÂ² = {results1.rsquared_within:.4f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# MODEL 2: SAFE HAVEN INTERACTION\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"MODEL 2: Safe Haven Interaction (REER Ã— Safe Haven)\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "df_clean2 = df_panel[['res_price_growth', 'reer_change_pct', 'reer_x_safe', \n",
    "                       'reer_volatility', 'reer_appreciation', 'res_price_lag1']].dropna()\n",
    "\n",
    "model2 = PanelOLS(\n",
    "    dependent=df_clean2['res_price_growth'],\n",
    "    exog=df_clean2[['reer_change_pct', 'reer_x_safe', 'reer_volatility', \n",
    "                     'reer_appreciation', 'res_price_lag1']],\n",
    "    entity_effects=True,\n",
    "    time_effects=True\n",
    ")\n",
    "results2 = model2.fit(cov_type='kernel', kernel='bartlett', bandwidth=4)\n",
    "\n",
    "print(f\"âœ“ Model 2: REER Change = {results2.params['reer_change_pct']:.4f} (p = {results2.pvalues['reer_change_pct']:.4f})\")\n",
    "print(f\"           REER Ã— Safe Haven = {results2.params['reer_x_safe']:.4f} (p = {results2.pvalues['reer_x_safe']:.4f})\")\n",
    "print(f\"           RÂ² = {results2.rsquared:.4f}, Within RÂ² = {results2.rsquared_within:.4f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# MODEL 3: CRISIS INTERACTION (WITHOUT TIME FE - CRISIS DUMMY INCLUDED)\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"MODEL 3: Crisis Interaction (REER Ã— Crisis) - NO TIME FE\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "df_clean3 = df_panel[['res_price_growth', 'reer_change_pct', 'reer_x_crisis', \n",
    "                       'reer_volatility', 'reer_appreciation', 'res_price_lag1', 'crisis']].dropna()\n",
    "\n",
    "model3 = PanelOLS(\n",
    "    dependent=df_clean3['res_price_growth'],\n",
    "    exog=df_clean3[['reer_change_pct', 'reer_x_crisis', 'crisis', 'reer_volatility', \n",
    "                     'reer_appreciation', 'res_price_lag1']],\n",
    "    entity_effects=True,\n",
    "    time_effects=False  # âœ… FIX: Remove time FE to avoid absorbing crisis dummy\n",
    ")\n",
    "results3 = model3.fit(cov_type='kernel', kernel='bartlett', bandwidth=4)\n",
    "\n",
    "print(f\"âœ“ Model 3: REER Change = {results3.params['reer_change_pct']:.4f} (p = {results3.pvalues['reer_change_pct']:.4f})\")\n",
    "print(f\"           REER Ã— Crisis = {results3.params['reer_x_crisis']:.4f} (p = {results3.pvalues['reer_x_crisis']:.4f})\")\n",
    "print(f\"           Crisis Dummy = {results3.params['crisis']:.4f} (p = {results3.pvalues['crisis']:.4f})\")\n",
    "print(f\"           RÂ² = {results3.rsquared:.4f}, Within RÂ² = {results3.rsquared_within:.4f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# MODEL 4: TRIPLE INTERACTION (MAIN RESULT!) - WITH TIME FE\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"MODEL 4: TRIPLE INTERACTION (REER Ã— Safe Ã— Crisis) - TIME FE ABSORBS CRISIS ðŸŽ¯\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "df_clean4 = df_panel[['res_price_growth', 'reer_change_pct', 'reer_x_safe', \n",
    "                       'reer_x_crisis', 'reer_x_safe_x_crisis',\n",
    "                       'reer_volatility', 'reer_appreciation', 'res_price_lag1']].dropna()\n",
    "\n",
    "model4 = PanelOLS(\n",
    "    dependent=df_clean4['res_price_growth'],\n",
    "    exog=df_clean4[['reer_change_pct', 'reer_x_safe', 'reer_x_crisis', \n",
    "                     'reer_x_safe_x_crisis', 'reer_volatility', \n",
    "                     'reer_appreciation', 'res_price_lag1']],\n",
    "    entity_effects=True,\n",
    "    time_effects=True  # âœ… Time FE absorbs crisis main effect (OK for interactions!)\n",
    ")\n",
    "results4 = model4.fit(cov_type='kernel', kernel='bartlett', bandwidth=4)\n",
    "\n",
    "print(f\"âœ“ Model 4: REER Change = {results4.params['reer_change_pct']:.4f} (p = {results4.pvalues['reer_change_pct']:.4f})\")\n",
    "print(f\"           REER Ã— Safe Haven = {results4.params['reer_x_safe']:.4f} (p = {results4.pvalues['reer_x_safe']:.4f})\")\n",
    "print(f\"           REER Ã— Crisis = {results4.params['reer_x_crisis']:.4f} (p = {results4.pvalues['reer_x_crisis']:.4f})\")\n",
    "print(f\"           REER Ã— Safe Ã— Crisis = {results4.params['reer_x_safe_x_crisis']:.4f} (p = {results4.pvalues['reer_x_safe_x_crisis']:.4f}) ðŸŽ¯\")\n",
    "print(f\"           RÂ² = {results4.rsquared:.4f}, Within RÂ² = {results4.rsquared_within:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"ðŸŽ¯ MAIN RESULTS (Model 4 - Triple Interaction)\")\n",
    "print(\"=\"*100)\n",
    "print(results4.summary)\n",
    "\n",
    "# ============================================================================\n",
    "# COMPUTE MARGINAL EFFECTS (FROM MODEL 4)\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"ðŸ“Š MARGINAL EFFECTS (Effect of 1% REER Appreciation)\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# Marginal effects from Model 4\n",
    "beta_reer = results4.params['reer_change_pct']\n",
    "beta_safe = results4.params['reer_x_safe']\n",
    "beta_crisis = results4.params['reer_x_crisis']\n",
    "beta_triple = results4.params['reer_x_safe_x_crisis']\n",
    "\n",
    "# Four scenarios\n",
    "normal_normal = beta_reer\n",
    "safe_normal = beta_reer + beta_safe\n",
    "normal_crisis = beta_reer + beta_crisis\n",
    "safe_crisis = beta_reer + beta_safe + beta_crisis + beta_triple\n",
    "\n",
    "print(f\"\\n1. Normal Countries, Normal Times:\")\n",
    "print(f\"   Effect: {normal_normal:.4f}\")\n",
    "print(f\"\\n2. Safe Haven Countries, Normal Times:\")\n",
    "print(f\"   Effect: {safe_normal:.4f}\")\n",
    "print(f\"   Difference from (1): {safe_normal - normal_normal:.4f}\")\n",
    "print(f\"\\n3. Normal Countries, Crisis Times:\")\n",
    "print(f\"   Effect: {normal_crisis:.4f}\")\n",
    "print(f\"   Difference from (1): {normal_crisis - normal_normal:.4f}\")\n",
    "print(f\"\\n4. Safe Haven Countries, Crisis Times: ðŸŽ¯\")\n",
    "print(f\"   Effect: {safe_crisis:.4f}\")\n",
    "print(f\"   Difference from (3): {safe_crisis - normal_crisis:.4f}\")\n",
    "print(f\"\\nðŸ’¡ FLIGHT-TO-SAFETY REVERSAL = {safe_crisis - normal_crisis:.4f}\")\n",
    "print(f\"   (How much MORE safe havens respond vs normal countries during crises)\")\n",
    "\n",
    "# ============================================================================\n",
    "# CREATE COMPARISON TABLE\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"ðŸ“Š CREATING COMPARISON TABLE\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "comparison_rows = []\n",
    "\n",
    "# Main variables\n",
    "variables = [\n",
    "    ('reer_change_pct', 'REER Change (%)'),\n",
    "    ('reer_x_safe', 'REER Ã— Safe Haven'),\n",
    "    ('reer_x_crisis', 'REER Ã— Crisis'),\n",
    "    ('reer_x_safe_x_crisis', 'REER Ã— Safe Ã— Crisis (TRIPLE)'),\n",
    "    ('crisis', 'Crisis Dummy'),\n",
    "    ('reer_volatility', 'REER Volatility'),\n",
    "    ('reer_appreciation', 'REER Appreciation'),\n",
    "    ('res_price_lag1', 'Lagged Property Price')\n",
    "]\n",
    "\n",
    "# Build table\n",
    "for var, label in variables:\n",
    "    coef_row = {'Variable': label}\n",
    "    se_row = {'Variable': ''}\n",
    "    \n",
    "    for i, res in enumerate([results1, results2, results3, results4], 1):\n",
    "        if var in res.params.index:\n",
    "            coef = res.params[var]\n",
    "            pval = res.pvalues[var]\n",
    "            se = res.std_errors[var]\n",
    "            stars = '***' if pval < 0.01 else ('**' if pval < 0.05 else ('*' if pval < 0.10 else ''))\n",
    "            coef_row[f'Model {i}'] = f\"{coef:.4f}{stars}\"\n",
    "            se_row[f'Model {i}'] = f\"({se:.4f})\"\n",
    "        else:\n",
    "            coef_row[f'Model {i}'] = 'â€”'\n",
    "            se_row[f'Model {i}'] = ''\n",
    "    \n",
    "    comparison_rows.append(coef_row)\n",
    "    comparison_rows.append(se_row)\n",
    "\n",
    "# Add blank row\n",
    "comparison_rows.append({'Variable': '', 'Model 1': '', 'Model 2': '', 'Model 3': '', 'Model 4': ''})\n",
    "\n",
    "# Model specs\n",
    "comparison_rows.append({'Variable': 'Country Fixed Effects', \n",
    "                       'Model 1': 'Yes', 'Model 2': 'Yes', 'Model 3': 'Yes', 'Model 4': 'Yes'})\n",
    "comparison_rows.append({'Variable': 'Time Fixed Effects', \n",
    "                       'Model 1': 'Yes', 'Model 2': 'Yes', 'Model 3': 'No', 'Model 4': 'Yes'})\n",
    "comparison_rows.append({'Variable': 'Standard Errors', \n",
    "                       'Model 1': 'Driscoll-Kraay', 'Model 2': 'Driscoll-Kraay', \n",
    "                       'Model 3': 'Driscoll-Kraay', 'Model 4': 'Driscoll-Kraay'})\n",
    "\n",
    "comparison_rows.append({'Variable': '', 'Model 1': '', 'Model 2': '', 'Model 3': '', 'Model 4': ''})\n",
    "\n",
    "# Statistics\n",
    "comparison_rows.append({'Variable': 'Observations', \n",
    "                       'Model 1': f\"{int(results1.nobs):,}\",\n",
    "                       'Model 2': f\"{int(results2.nobs):,}\",\n",
    "                       'Model 3': f\"{int(results3.nobs):,}\",\n",
    "                       'Model 4': f\"{int(results4.nobs):,}\"})\n",
    "\n",
    "comparison_rows.append({'Variable': 'RÂ²', \n",
    "                       'Model 1': f\"{results1.rsquared:.4f}\",\n",
    "                       'Model 2': f\"{results2.rsquared:.4f}\",\n",
    "                       'Model 3': f\"{results3.rsquared:.4f}\",\n",
    "                       'Model 4': f\"{results4.rsquared:.4f}\"})\n",
    "\n",
    "comparison_rows.append({'Variable': 'Within RÂ²', \n",
    "                       'Model 1': f\"{results1.rsquared_within:.4f}\",\n",
    "                       'Model 2': f\"{results2.rsquared_within:.4f}\",\n",
    "                       'Model 3': f\"{results3.rsquared_within:.4f}\",\n",
    "                       'Model 4': f\"{results4.rsquared_within:.4f}\"})\n",
    "\n",
    "# Create DataFrame\n",
    "comparison_df = pd.DataFrame(comparison_rows)\n",
    "\n",
    "# Save\n",
    "comparison_df.to_excel(OUTPUT_PATH + 'tables/Crisis_Interaction_Models.xlsx', index=False)\n",
    "comparison_df.to_csv(OUTPUT_PATH + 'tables/Crisis_Interaction_Models.csv', index=False)\n",
    "\n",
    "print(\"âœ“ Table saved: Crisis_Interaction_Models\")\n",
    "print(\"\\n\" + comparison_df.to_string(index=False))\n",
    "\n",
    "# ============================================================================\n",
    "# MARGINAL EFFECTS TABLE\n",
    "# ============================================================================\n",
    "marginal_df = pd.DataFrame({\n",
    "    'Scenario': [\n",
    "        '1. Normal Countries, Normal Times',\n",
    "        '2. Safe Haven Countries, Normal Times',\n",
    "        '3. Normal Countries, Crisis Times',\n",
    "        '4. Safe Haven Countries, Crisis Times ðŸŽ¯'\n",
    "    ],\n",
    "    'Marginal Effect': [\n",
    "        f\"{normal_normal:.4f}\",\n",
    "        f\"{safe_normal:.4f}\",\n",
    "        f\"{normal_crisis:.4f}\",\n",
    "        f\"{safe_crisis:.4f}\"\n",
    "    ],\n",
    "    'vs Normal/Normal': [\n",
    "        'â€”',\n",
    "        f\"{safe_normal - normal_normal:+.4f}\",\n",
    "        f\"{normal_crisis - normal_normal:+.4f}\",\n",
    "        f\"{safe_crisis - normal_normal:+.4f}\"\n",
    "    ],\n",
    "    'Interpretation': [\n",
    "        'Baseline effect (normal countries, normal times)',\n",
    "        'Safe haven premium in normal times',\n",
    "        'Crisis effect for normal countries',\n",
    "        'FLIGHT-TO-SAFETY: Safe haven during crisis'\n",
    "    ]\n",
    "})\n",
    "\n",
    "marginal_df.to_excel(OUTPUT_PATH + 'tables/Marginal_Effects_Scenarios.xlsx', index=False)\n",
    "marginal_df.to_csv(OUTPUT_PATH + 'tables/Marginal_Effects_Scenarios.csv', index=False)\n",
    "\n",
    "print(\"\\nâœ“ Table saved: Marginal_Effects_Scenarios\")\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"ðŸ“Š MARGINAL EFFECTS TABLE\")\n",
    "print(\"=\"*100)\n",
    "print(marginal_df.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"âœ… CRISIS INTERACTION MODELS COMPLETE!\")\n",
    "print(\"=\"*100)\n",
    "print(f\"\\nðŸ“ Location: {OUTPUT_PATH}tables/\")\n",
    "print(\"\\nðŸŽ¯ KEY FINDING (Triple Interaction):\")\n",
    "print(f\"   Î² (REER Ã— Safe Ã— Crisis) = {results4.params['reer_x_safe_x_crisis']:.4f}\")\n",
    "print(f\"   P-value = {results4.pvalues['reer_x_safe_x_crisis']:.4f}\")\n",
    "print(f\"   {'âœ… SIGNIFICANT!' if results4.pvalues['reer_x_safe_x_crisis'] < 0.10 else 'âŒ Not significant (yet)'}\")\n",
    "print(\"\\nðŸ’¡ INTERPRETATION:\")\n",
    "print(\"   â€¢ Triple interaction tests if safe haven effect REVERSES during crises\")\n",
    "print(\"   â€¢ Positive coefficient = flight-to-safety strengthens property prices\")\n",
    "print(\"   â€¢ Model 4 uses Time FE (absorbs crisis main effect, keeps interactions)\")\n",
    "print(\"=\"*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6087ab09-6c12-45d3-a1e3-4eab850c2cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "ðŸŒ¡ï¸ CRISIS INTENSITY MODEL - CONTINUOUS SPECIFICATION\n",
      "====================================================================================================\n",
      "\n",
      "====================================================================================================\n",
      "ðŸš¨ DEFINING CRISIS PERIODS\n",
      "====================================================================================================\n",
      "âœ“ Crisis periods defined (28% of observations)\n",
      "\n",
      "====================================================================================================\n",
      "ðŸŒ¡ï¸ CREATING CRISIS INTENSITY VARIABLE (CONTINUOUS)\n",
      "====================================================================================================\n",
      "âœ“ Crisis Intensity Variable Created:\n",
      "   â€¢ Based on: REER Volatility during crisis periods\n",
      "   â€¢ Mean (crisis periods): 0.0244\n",
      "   â€¢ Std (crisis periods): 0.0316\n",
      "   â€¢ Min: 0.0000, Max: 0.3990\n",
      "\n",
      "âœ“ Alternative Intensity (Absolute REER Change):\n",
      "   â€¢ Mean (crisis periods): 2.0720\n",
      "   â€¢ Std (crisis periods): 3.3416\n",
      "\n",
      "====================================================================================================\n",
      "ðŸ”§ CREATING INTERACTION TERMS WITH INTENSITY\n",
      "====================================================================================================\n",
      "âœ“ Interaction terms created:\n",
      "   â€¢ reer_x_intensity: REER Ã— Crisis Intensity (continuous)\n",
      "   â€¢ reer_x_safe_x_intensity: REER Ã— Safe Ã— Intensity (TRIPLE)\n",
      "\n",
      "ðŸ“Š Data: 2,900 observations, 29 countries\n",
      "\n",
      "====================================================================================================\n",
      "MODEL 5: Crisis Intensity (Continuous) - No Interaction\n",
      "====================================================================================================\n",
      "âœ“ Model 5: REER Change = 0.0025 (p = 0.9727)\n",
      "           REER Ã— Intensity = -0.0044 (p = 0.5306)\n",
      "           RÂ² = 0.0016, Within RÂ² = 0.0017\n",
      "\n",
      "====================================================================================================\n",
      "MODEL 6: Safe Haven Ã— Intensity (Two-way)\n",
      "====================================================================================================\n",
      "âœ“ Model 6: REER Change = 0.0022 (p = 0.9752)\n",
      "           REER Ã— Safe Haven = 0.0047 (p = 0.9311)\n",
      "           REER Ã— Intensity = -0.0044 (p = 0.5312)\n",
      "           RÂ² = 0.0016, Within RÂ² = 0.0017\n",
      "\n",
      "====================================================================================================\n",
      "MODEL 7: TRIPLE INTERACTION (REER Ã— Safe Ã— Intensity) ðŸŽ¯\n",
      "====================================================================================================\n",
      "âœ“ Model 7: REER Change = 0.0035 (p = 0.9616)\n",
      "           REER Ã— Safe Haven = 0.0255 (p = 0.6565)\n",
      "           REER Ã— Intensity = -0.0044 (p = 0.5280)\n",
      "           REER Ã— Safe Ã— Intensity = -0.4701 (p = 0.1200) ðŸŽ¯\n",
      "           RÂ² = 0.0016, Within RÂ² = 0.0018\n",
      "\n",
      "====================================================================================================\n",
      "ðŸŽ¯ MAIN RESULTS (Model 7 - Triple Interaction with Intensity)\n",
      "====================================================================================================\n",
      "                          PanelOLS Estimation Summary                           \n",
      "================================================================================\n",
      "Dep. Variable:       res_price_growth   R-squared:                        0.0016\n",
      "Estimator:                   PanelOLS   R-squared (Between):             -0.4087\n",
      "No. Observations:                2811   R-squared (Within):               0.0018\n",
      "Date:                Tue, Dec 09 2025   R-squared (Overall):             -0.0091\n",
      "Time:                        22:44:13   Log-likelihood                   -9912.3\n",
      "Cov. Estimator:        Driscoll-Kraay                                           \n",
      "                                        F-statistic:                      0.6316\n",
      "Entities:                          29   P-value                           0.7301\n",
      "Avg Obs:                       96.931   Distribution:                  F(7,2678)\n",
      "Min Obs:                       91.000                                           \n",
      "Max Obs:                       98.000   F-statistic (robust):             1.9838\n",
      "                                        P-value                           0.0537\n",
      "Time periods:                      98   Distribution:                  F(7,2678)\n",
      "Avg Obs:                       28.684                                           \n",
      "Min Obs:                       24.000                                           \n",
      "Max Obs:                       29.000                                           \n",
      "                                                                                \n",
      "                                    Parameter Estimates                                    \n",
      "===========================================================================================\n",
      "                         Parameter  Std. Err.     T-stat    P-value    Lower CI    Upper CI\n",
      "-------------------------------------------------------------------------------------------\n",
      "reer_change_pct             0.0035     0.0720     0.0482     0.9616     -0.1377      0.1447\n",
      "reer_x_safe                 0.0255     0.0574     0.4448     0.6565     -0.0870      0.1380\n",
      "reer_x_intensity           -0.0044     0.0070    -0.6312     0.5280     -0.0180      0.0092\n",
      "reer_x_safe_x_intensity    -0.4701     0.3023    -1.5552     0.1200     -1.0629      0.1226\n",
      "reer_volatility             5.0736     4.9349     1.0281     0.3040     -4.6030      14.750\n",
      "reer_appreciation           0.1240     0.5462     0.2270     0.8204     -0.9470      1.1950\n",
      "res_price_lag1          -7.479e-05  3.191e-05    -2.3437     0.0192     -0.0001  -1.222e-05\n",
      "===========================================================================================\n",
      "\n",
      "F-test for Poolability: 0.7770\n",
      "P-value: 0.9669\n",
      "Distribution: F(125,2678)\n",
      "\n",
      "Included effects: Entity, Time\n",
      "\n",
      "====================================================================================================\n",
      "ðŸ“Š COMPARING DUMMY vs INTENSITY SPECIFICATIONS\n",
      "====================================================================================================\n",
      "\n",
      "ðŸ“Š COMPARISON:\n",
      "\n",
      "   DUMMY SPECIFICATION (Model 4):\n",
      "      REER Ã— Safe Ã— Crisis (dummy) = 0.0312 (p = 0.7435)\n",
      "      RÂ² = 0.0022\n",
      "\n",
      "   INTENSITY SPECIFICATION (Model 7):\n",
      "      REER Ã— Safe Ã— Intensity (continuous) = -0.4701 (p = 0.1200)\n",
      "      RÂ² = 0.0016\n",
      "\n",
      "====================================================================================================\n",
      "ðŸ“Š MARGINAL EFFECTS (Crisis Intensity Model)\n",
      "====================================================================================================\n",
      "\n",
      "ðŸ“Š Effect of 1% REER Appreciation at Different Crisis Intensities:\n",
      "\n",
      "Normal Times (Intensity = 0):\n",
      "   Normal Countries: 0.0035\n",
      "   Safe Haven Countries: 0.0290\n",
      "   Difference (Safe - Normal): 0.0255\n",
      "\n",
      "Moderate Crisis (Intensity = +1 SD):\n",
      "   Normal Countries: -0.0009\n",
      "   Safe Haven Countries: -0.4455\n",
      "   Difference (Safe - Normal): -0.4446\n",
      "\n",
      "Severe Crisis (Intensity = +2 SD):\n",
      "   Normal Countries: -0.0053\n",
      "   Safe Haven Countries: -0.9201\n",
      "   Difference (Safe - Normal): -0.9147\n",
      "\n",
      "====================================================================================================\n",
      "ðŸ“Š CREATING COMPREHENSIVE COMPARISON TABLE\n",
      "====================================================================================================\n",
      "âœ“ Table saved: Dummy_vs_Intensity_Comparison\n",
      "\n",
      "                            Variable      Model 1        Model 2        Model 3            Model 4\n",
      "                     REER Change (%)       0.0731         0.0025         0.0022             0.0035\n",
      "                                         (0.0665)       (0.0723)       (0.0722)           (0.0720)\n",
      "                   REER Ã— Safe Haven      -0.0074              â€”         0.0047             0.0255\n",
      "                                         (0.0611)                      (0.0542)           (0.0574)\n",
      "               REER Ã— Crisis (Dummy)   -0.1513***              â€”              â€”                  â€”\n",
      "                                         (0.0549)                                                 \n",
      "             REER Ã— Crisis Intensity            â€”        -0.0044        -0.0044            -0.0044\n",
      "                                                        (0.0070)       (0.0070)           (0.0070)\n",
      "        REER Ã— Safe Ã— Crisis (DUMMY)       0.0312              â€”              â€”                  â€”\n",
      "                                         (0.0953)                                                 \n",
      "REER Ã— Safe Ã— Intensity (CONTINUOUS)            â€”              â€”              â€”            -0.4701\n",
      "                                                                                          (0.3023)\n",
      "                     REER Volatility       5.8140         5.1251         5.1265             5.0736\n",
      "                                         (5.1235)       (4.9185)       (4.9266)           (4.9349)\n",
      "                   REER Appreciation       0.0539         0.1352         0.1343             0.1240\n",
      "                                         (0.5051)       (0.5435)       (0.5466)           (0.5462)\n",
      "               Lagged Property Price    -0.0001**      -0.0001**      -0.0001**          -0.0001**\n",
      "                                         (0.0000)       (0.0000)       (0.0000)           (0.0000)\n",
      "                                                                                                  \n",
      "                       Specification Crisis Dummy Intensity Only Intensity+Safe Triple (Intensity)\n",
      "               Country Fixed Effects          Yes            Yes            Yes                Yes\n",
      "                  Time Fixed Effects          Yes            Yes            Yes                Yes\n",
      "                                                                                                  \n",
      "                        Observations        2,811          2,811          2,811              2,811\n",
      "                                  RÂ²       0.0022         0.0016         0.0016             0.0016\n",
      "                           Within RÂ²       0.0024         0.0017         0.0017             0.0018\n",
      "\n",
      "âœ“ Table saved: Marginal_Effects_Intensity\n",
      "\n",
      "====================================================================================================\n",
      "ðŸ“Š MARGINAL EFFECTS BY INTENSITY LEVEL\n",
      "====================================================================================================\n",
      "                    Intensity Level Normal Countries Safe Haven Difference\n",
      "       Normal Times (Intensity = 0)           0.0035     0.0290     0.0255\n",
      "Moderate Crisis (Intensity = +1 SD)          -0.0009    -0.4455    -0.4446\n",
      "  Severe Crisis (Intensity = +2 SD)          -0.0053    -0.9201    -0.9147\n",
      "\n",
      "====================================================================================================\n",
      "âœ… CRISIS INTENSITY MODELS COMPLETE!\n",
      "====================================================================================================\n",
      "\n",
      "ðŸ“ Location: C:\\Users\\dirir\\OneDrive\\ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—\\Semester 1\\houses\\house\\workingfile\\crisis_models\\\\tables/\n",
      "\n",
      "ðŸŽ¯ KEY COMPARISON:\n",
      "   Dummy Specification:\n",
      "      Î² (REER Ã— Safe Ã— Crisis) = 0.0312 (p = 0.7435)\n",
      "\n",
      "   Intensity Specification:\n",
      "      Î² (REER Ã— Safe Ã— Intensity) = -0.4701 (p = 0.1200)\n",
      "\n",
      "ðŸ’¡ Intensity specification provides:\n",
      "   â€¢ More variation (continuous vs binary)\n",
      "   â€¢ Better power to detect effects\n",
      "   â€¢ Distinguishes mild vs severe crises\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from linearmodels.panel import PanelOLS\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ============================================================================\n",
    "# CRISIS INTENSITY MODEL - CONTINUOUS MEASURE (IMPROVED SPECIFICATION)\n",
    "# ============================================================================\n",
    "\n",
    "DATA_PATH = r\"C:\\Users\\dirir\\OneDrive\\ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—\\Semester 1\\houses\\house\\workingfile\\\\\"\n",
    "OUTPUT_PATH = r\"C:\\Users\\dirir\\OneDrive\\ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—\\Semester 1\\houses\\house\\workingfile\\crisis_models\\\\\"\n",
    "\n",
    "import os\n",
    "os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
    "os.makedirs(OUTPUT_PATH + 'tables', exist_ok=True)\n",
    "\n",
    "print(\"=\"*100)\n",
    "print(\"ðŸŒ¡ï¸ CRISIS INTENSITY MODEL - CONTINUOUS SPECIFICATION\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# ============================================================================\n",
    "# LOAD DATA\n",
    "# ============================================================================\n",
    "df = pd.read_csv(DATA_PATH + 'panel_balanced_residential.csv')\n",
    "\n",
    "# Create safe haven variable\n",
    "SAFE_HAVEN = ['US: United States', 'JP: Japan', 'CH: Switzerland', 'DE: Germany']\n",
    "df['safe_haven'] = df['country_code'].isin(SAFE_HAVEN).astype(int)\n",
    "\n",
    "# Create lagged variable if not exists\n",
    "if 'res_price_lag1' not in df.columns:\n",
    "    df = df.sort_values(['country_code', 'year', 'quarter'])\n",
    "    df['res_price_lag1'] = df.groupby('country_code')['residential_price'].shift(1)\n",
    "\n",
    "# ============================================================================\n",
    "# CREATE CRISIS DUMMY (SAME AS BEFORE)\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"ðŸš¨ DEFINING CRISIS PERIODS\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "df['crisis'] = 0\n",
    "\n",
    "# Global Financial Crisis (2008-2009)\n",
    "df.loc[(df['year'] >= 2008) & (df['year'] <= 2009), 'crisis'] = 1\n",
    "\n",
    "# European Debt Crisis (2011-2012)\n",
    "df.loc[(df['year'] >= 2011) & (df['year'] <= 2012), 'crisis'] = 1\n",
    "\n",
    "# COVID-19 Pandemic (2020-2021)\n",
    "df.loc[(df['year'] >= 2020) & (df['year'] <= 2021), 'crisis'] = 1\n",
    "\n",
    "# Ukraine War / Energy Crisis (2022)\n",
    "df.loc[df['year'] == 2022, 'crisis'] = 1\n",
    "\n",
    "print(f\"âœ“ Crisis periods defined (28% of observations)\")\n",
    "\n",
    "# ============================================================================\n",
    "# CREATE CRISIS INTENSITY MEASURE (CONTINUOUS)\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"ðŸŒ¡ï¸ CREATING CRISIS INTENSITY VARIABLE (CONTINUOUS)\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# METHOD 1: Use REER Volatility as Crisis Intensity\n",
    "# Higher volatility during crisis periods = more intense crisis\n",
    "df['crisis_intensity'] = df['reer_volatility'] * df['crisis']\n",
    "\n",
    "# Standardize intensity (mean=0, sd=1) for easier interpretation\n",
    "crisis_intensity_std = df[df['crisis'] == 1]['crisis_intensity'].std()\n",
    "crisis_intensity_mean = df[df['crisis'] == 1]['crisis_intensity'].mean()\n",
    "\n",
    "if crisis_intensity_std > 0:\n",
    "    df['crisis_intensity_std'] = (df['crisis_intensity'] - crisis_intensity_mean) / crisis_intensity_std\n",
    "else:\n",
    "    df['crisis_intensity_std'] = df['crisis_intensity']\n",
    "\n",
    "# Set to 0 during non-crisis periods\n",
    "df.loc[df['crisis'] == 0, 'crisis_intensity_std'] = 0\n",
    "\n",
    "print(f\"âœ“ Crisis Intensity Variable Created:\")\n",
    "print(f\"   â€¢ Based on: REER Volatility during crisis periods\")\n",
    "print(f\"   â€¢ Mean (crisis periods): {df[df['crisis']==1]['crisis_intensity'].mean():.4f}\")\n",
    "print(f\"   â€¢ Std (crisis periods): {df[df['crisis']==1]['crisis_intensity'].std():.4f}\")\n",
    "print(f\"   â€¢ Min: {df['crisis_intensity'].min():.4f}, Max: {df['crisis_intensity'].max():.4f}\")\n",
    "\n",
    "# Alternative: Create intensity from absolute REER changes during crises\n",
    "df['crisis_intensity_alt'] = np.abs(df['reer_change_pct']) * df['crisis']\n",
    "\n",
    "print(f\"\\nâœ“ Alternative Intensity (Absolute REER Change):\")\n",
    "print(f\"   â€¢ Mean (crisis periods): {df[df['crisis']==1]['crisis_intensity_alt'].mean():.4f}\")\n",
    "print(f\"   â€¢ Std (crisis periods): {df[df['crisis']==1]['crisis_intensity_alt'].std():.4f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# CREATE INTERACTION TERMS WITH INTENSITY\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"ðŸ”§ CREATING INTERACTION TERMS WITH INTENSITY\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# Primary specification: Use standardized volatility-based intensity\n",
    "df['reer_x_intensity'] = df['reer_change_pct'] * df['crisis_intensity_std']\n",
    "df['reer_x_safe_x_intensity'] = df['reer_change_pct'] * df['safe_haven'] * df['crisis_intensity_std']\n",
    "\n",
    "# Also keep dummy interactions for comparison\n",
    "df['reer_x_safe'] = df['reer_change_pct'] * df['safe_haven']\n",
    "df['reer_x_crisis'] = df['reer_change_pct'] * df['crisis']\n",
    "df['reer_x_safe_x_crisis'] = df['reer_change_pct'] * df['safe_haven'] * df['crisis']\n",
    "\n",
    "print(\"âœ“ Interaction terms created:\")\n",
    "print(\"   â€¢ reer_x_intensity: REER Ã— Crisis Intensity (continuous)\")\n",
    "print(\"   â€¢ reer_x_safe_x_intensity: REER Ã— Safe Ã— Intensity (TRIPLE)\")\n",
    "\n",
    "# Create NUMERIC time index\n",
    "df['time_numeric'] = df['year'] + (df['quarter'] - 1) / 4\n",
    "\n",
    "# Set MultiIndex\n",
    "df_panel = df.set_index(['country_code', 'time_numeric'])\n",
    "\n",
    "print(f\"\\nðŸ“Š Data: {len(df):,} observations, {df['country_code'].nunique()} countries\")\n",
    "\n",
    "# ============================================================================\n",
    "# MODEL 5: CRISIS INTENSITY (CONTINUOUS) - NO SAFE HAVEN INTERACTION\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"MODEL 5: Crisis Intensity (Continuous) - No Interaction\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "df_clean5 = df_panel[['res_price_growth', 'reer_change_pct', 'reer_x_intensity',\n",
    "                       'reer_volatility', 'reer_appreciation', 'res_price_lag1']].dropna()\n",
    "\n",
    "model5 = PanelOLS(\n",
    "    dependent=df_clean5['res_price_growth'],\n",
    "    exog=df_clean5[['reer_change_pct', 'reer_x_intensity', 'reer_volatility', \n",
    "                     'reer_appreciation', 'res_price_lag1']],\n",
    "    entity_effects=True,\n",
    "    time_effects=True\n",
    ")\n",
    "results5 = model5.fit(cov_type='kernel', kernel='bartlett', bandwidth=4)\n",
    "\n",
    "print(f\"âœ“ Model 5: REER Change = {results5.params['reer_change_pct']:.4f} (p = {results5.pvalues['reer_change_pct']:.4f})\")\n",
    "print(f\"           REER Ã— Intensity = {results5.params['reer_x_intensity']:.4f} (p = {results5.pvalues['reer_x_intensity']:.4f})\")\n",
    "print(f\"           RÂ² = {results5.rsquared:.4f}, Within RÂ² = {results5.rsquared_within:.4f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# MODEL 6: SAFE HAVEN Ã— INTENSITY INTERACTION\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"MODEL 6: Safe Haven Ã— Intensity (Two-way)\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "df_clean6 = df_panel[['res_price_growth', 'reer_change_pct', 'reer_x_safe', \n",
    "                       'reer_x_intensity', 'reer_volatility', 'reer_appreciation', \n",
    "                       'res_price_lag1']].dropna()\n",
    "\n",
    "model6 = PanelOLS(\n",
    "    dependent=df_clean6['res_price_growth'],\n",
    "    exog=df_clean6[['reer_change_pct', 'reer_x_safe', 'reer_x_intensity', \n",
    "                     'reer_volatility', 'reer_appreciation', 'res_price_lag1']],\n",
    "    entity_effects=True,\n",
    "    time_effects=True\n",
    ")\n",
    "results6 = model6.fit(cov_type='kernel', kernel='bartlett', bandwidth=4)\n",
    "\n",
    "print(f\"âœ“ Model 6: REER Change = {results6.params['reer_change_pct']:.4f} (p = {results6.pvalues['reer_change_pct']:.4f})\")\n",
    "print(f\"           REER Ã— Safe Haven = {results6.params['reer_x_safe']:.4f} (p = {results6.pvalues['reer_x_safe']:.4f})\")\n",
    "print(f\"           REER Ã— Intensity = {results6.params['reer_x_intensity']:.4f} (p = {results6.pvalues['reer_x_intensity']:.4f})\")\n",
    "print(f\"           RÂ² = {results6.rsquared:.4f}, Within RÂ² = {results6.rsquared_within:.4f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# MODEL 7: TRIPLE INTERACTION WITH INTENSITY (MAIN RESULT!)\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"MODEL 7: TRIPLE INTERACTION (REER Ã— Safe Ã— Intensity) ðŸŽ¯\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "df_clean7 = df_panel[['res_price_growth', 'reer_change_pct', 'reer_x_safe', \n",
    "                       'reer_x_intensity', 'reer_x_safe_x_intensity',\n",
    "                       'reer_volatility', 'reer_appreciation', 'res_price_lag1']].dropna()\n",
    "\n",
    "model7 = PanelOLS(\n",
    "    dependent=df_clean7['res_price_growth'],\n",
    "    exog=df_clean7[['reer_change_pct', 'reer_x_safe', 'reer_x_intensity', \n",
    "                     'reer_x_safe_x_intensity', 'reer_volatility', \n",
    "                     'reer_appreciation', 'res_price_lag1']],\n",
    "    entity_effects=True,\n",
    "    time_effects=True\n",
    ")\n",
    "results7 = model7.fit(cov_type='kernel', kernel='bartlett', bandwidth=4)\n",
    "\n",
    "print(f\"âœ“ Model 7: REER Change = {results7.params['reer_change_pct']:.4f} (p = {results7.pvalues['reer_change_pct']:.4f})\")\n",
    "print(f\"           REER Ã— Safe Haven = {results7.params['reer_x_safe']:.4f} (p = {results7.pvalues['reer_x_safe']:.4f})\")\n",
    "print(f\"           REER Ã— Intensity = {results7.params['reer_x_intensity']:.4f} (p = {results7.pvalues['reer_x_intensity']:.4f})\")\n",
    "print(f\"           REER Ã— Safe Ã— Intensity = {results7.params['reer_x_safe_x_intensity']:.4f} (p = {results7.pvalues['reer_x_safe_x_intensity']:.4f}) ðŸŽ¯\")\n",
    "print(f\"           RÂ² = {results7.rsquared:.4f}, Within RÂ² = {results7.rsquared_within:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"ðŸŽ¯ MAIN RESULTS (Model 7 - Triple Interaction with Intensity)\")\n",
    "print(\"=\"*100)\n",
    "print(results7.summary)\n",
    "\n",
    "# ============================================================================\n",
    "# LOAD PREVIOUS DUMMY RESULTS FOR COMPARISON\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"ðŸ“Š COMPARING DUMMY vs INTENSITY SPECIFICATIONS\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# Re-run Model 4 (dummy) for direct comparison\n",
    "df_clean4 = df_panel[['res_price_growth', 'reer_change_pct', 'reer_x_safe', \n",
    "                       'reer_x_crisis', 'reer_x_safe_x_crisis',\n",
    "                       'reer_volatility', 'reer_appreciation', 'res_price_lag1']].dropna()\n",
    "\n",
    "model4 = PanelOLS(\n",
    "    dependent=df_clean4['res_price_growth'],\n",
    "    exog=df_clean4[['reer_change_pct', 'reer_x_safe', 'reer_x_crisis', \n",
    "                     'reer_x_safe_x_crisis', 'reer_volatility', \n",
    "                     'reer_appreciation', 'res_price_lag1']],\n",
    "    entity_effects=True,\n",
    "    time_effects=True\n",
    ")\n",
    "results4 = model4.fit(cov_type='kernel', kernel='bartlett', bandwidth=4)\n",
    "\n",
    "print(f\"\\nðŸ“Š COMPARISON:\")\n",
    "print(f\"\\n   DUMMY SPECIFICATION (Model 4):\")\n",
    "print(f\"      REER Ã— Safe Ã— Crisis (dummy) = {results4.params['reer_x_safe_x_crisis']:.4f} (p = {results4.pvalues['reer_x_safe_x_crisis']:.4f})\")\n",
    "print(f\"      RÂ² = {results4.rsquared:.4f}\")\n",
    "print(f\"\\n   INTENSITY SPECIFICATION (Model 7):\")\n",
    "print(f\"      REER Ã— Safe Ã— Intensity (continuous) = {results7.params['reer_x_safe_x_intensity']:.4f} (p = {results7.pvalues['reer_x_safe_x_intensity']:.4f})\")\n",
    "print(f\"      RÂ² = {results7.rsquared:.4f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# MARGINAL EFFECTS FOR INTENSITY MODEL\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"ðŸ“Š MARGINAL EFFECTS (Crisis Intensity Model)\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "beta_reer = results7.params['reer_change_pct']\n",
    "beta_safe = results7.params['reer_x_safe']\n",
    "beta_intensity = results7.params['reer_x_intensity']\n",
    "beta_triple = results7.params['reer_x_safe_x_intensity']\n",
    "\n",
    "# Evaluate at different intensity levels\n",
    "intensity_levels = [0, 1, 2]  # 0 = normal, 1 = 1 SD above, 2 = 2 SD above\n",
    "\n",
    "print(\"\\nðŸ“Š Effect of 1% REER Appreciation at Different Crisis Intensities:\")\n",
    "\n",
    "marginal_data = []\n",
    "\n",
    "for intensity in intensity_levels:\n",
    "    normal_effect = beta_reer + beta_intensity * intensity\n",
    "    safe_effect = beta_reer + beta_safe + beta_intensity * intensity + beta_triple * intensity\n",
    "    \n",
    "    if intensity == 0:\n",
    "        label = \"Normal Times (Intensity = 0)\"\n",
    "    elif intensity == 1:\n",
    "        label = \"Moderate Crisis (Intensity = +1 SD)\"\n",
    "    else:\n",
    "        label = \"Severe Crisis (Intensity = +2 SD)\"\n",
    "    \n",
    "    print(f\"\\n{label}:\")\n",
    "    print(f\"   Normal Countries: {normal_effect:.4f}\")\n",
    "    print(f\"   Safe Haven Countries: {safe_effect:.4f}\")\n",
    "    print(f\"   Difference (Safe - Normal): {safe_effect - normal_effect:.4f}\")\n",
    "    \n",
    "    marginal_data.append({\n",
    "        'Intensity Level': label,\n",
    "        'Normal Countries': f\"{normal_effect:.4f}\",\n",
    "        'Safe Haven': f\"{safe_effect:.4f}\",\n",
    "        'Difference': f\"{safe_effect - normal_effect:.4f}\"\n",
    "    })\n",
    "\n",
    "# ============================================================================\n",
    "# CREATE COMPARISON TABLE\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"ðŸ“Š CREATING COMPREHENSIVE COMPARISON TABLE\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "comparison_rows = []\n",
    "\n",
    "# Variables\n",
    "variables = [\n",
    "    ('reer_change_pct', 'REER Change (%)'),\n",
    "    ('reer_x_safe', 'REER Ã— Safe Haven'),\n",
    "    ('reer_x_crisis', 'REER Ã— Crisis (Dummy)'),\n",
    "    ('reer_x_intensity', 'REER Ã— Crisis Intensity'),\n",
    "    ('reer_x_safe_x_crisis', 'REER Ã— Safe Ã— Crisis (DUMMY)'),\n",
    "    ('reer_x_safe_x_intensity', 'REER Ã— Safe Ã— Intensity (CONTINUOUS)'),\n",
    "    ('reer_volatility', 'REER Volatility'),\n",
    "    ('reer_appreciation', 'REER Appreciation'),\n",
    "    ('res_price_lag1', 'Lagged Property Price')\n",
    "]\n",
    "\n",
    "# Build table (Models 4, 5, 6, 7)\n",
    "for var, label in variables:\n",
    "    coef_row = {'Variable': label}\n",
    "    se_row = {'Variable': ''}\n",
    "    \n",
    "    for i, (res, name) in enumerate([(results4, 'Dummy'), (results5, 'Intensity'), \n",
    "                                      (results6, 'Intensity+Safe'), (results7, 'Triple Intensity')], 1):\n",
    "        col_name = f'Model {i}'\n",
    "        if var in res.params.index:\n",
    "            coef = res.params[var]\n",
    "            pval = res.pvalues[var]\n",
    "            se = res.std_errors[var]\n",
    "            stars = '***' if pval < 0.01 else ('**' if pval < 0.05 else ('*' if pval < 0.10 else ''))\n",
    "            coef_row[col_name] = f\"{coef:.4f}{stars}\"\n",
    "            se_row[col_name] = f\"({se:.4f})\"\n",
    "        else:\n",
    "            coef_row[col_name] = 'â€”'\n",
    "            se_row[col_name] = ''\n",
    "    \n",
    "    comparison_rows.append(coef_row)\n",
    "    comparison_rows.append(se_row)\n",
    "\n",
    "# Add blank row\n",
    "comparison_rows.append({'Variable': '', 'Model 1': '', 'Model 2': '', 'Model 3': '', 'Model 4': ''})\n",
    "\n",
    "# Model specs\n",
    "comparison_rows.append({'Variable': 'Specification', \n",
    "                       'Model 1': 'Crisis Dummy', 'Model 2': 'Intensity Only', \n",
    "                       'Model 3': 'Intensity+Safe', 'Model 4': 'Triple (Intensity)'})\n",
    "comparison_rows.append({'Variable': 'Country Fixed Effects', \n",
    "                       'Model 1': 'Yes', 'Model 2': 'Yes', 'Model 3': 'Yes', 'Model 4': 'Yes'})\n",
    "comparison_rows.append({'Variable': 'Time Fixed Effects', \n",
    "                       'Model 1': 'Yes', 'Model 2': 'Yes', 'Model 3': 'Yes', 'Model 4': 'Yes'})\n",
    "\n",
    "comparison_rows.append({'Variable': '', 'Model 1': '', 'Model 2': '', 'Model 3': '', 'Model 4': ''})\n",
    "\n",
    "# Statistics\n",
    "comparison_rows.append({'Variable': 'Observations', \n",
    "                       'Model 1': f\"{int(results4.nobs):,}\",\n",
    "                       'Model 2': f\"{int(results5.nobs):,}\",\n",
    "                       'Model 3': f\"{int(results6.nobs):,}\",\n",
    "                       'Model 4': f\"{int(results7.nobs):,}\"})\n",
    "\n",
    "comparison_rows.append({'Variable': 'RÂ²', \n",
    "                       'Model 1': f\"{results4.rsquared:.4f}\",\n",
    "                       'Model 2': f\"{results5.rsquared:.4f}\",\n",
    "                       'Model 3': f\"{results6.rsquared:.4f}\",\n",
    "                       'Model 4': f\"{results7.rsquared:.4f}\"})\n",
    "\n",
    "comparison_rows.append({'Variable': 'Within RÂ²', \n",
    "                       'Model 1': f\"{results4.rsquared_within:.4f}\",\n",
    "                       'Model 2': f\"{results5.rsquared_within:.4f}\",\n",
    "                       'Model 3': f\"{results6.rsquared_within:.4f}\",\n",
    "                       'Model 4': f\"{results7.rsquared_within:.4f}\"})\n",
    "\n",
    "# Create DataFrame\n",
    "comparison_df = pd.DataFrame(comparison_rows)\n",
    "\n",
    "# Save\n",
    "comparison_df.to_excel(OUTPUT_PATH + 'tables/Dummy_vs_Intensity_Comparison.xlsx', index=False)\n",
    "comparison_df.to_csv(OUTPUT_PATH + 'tables/Dummy_vs_Intensity_Comparison.csv', index=False)\n",
    "\n",
    "print(\"âœ“ Table saved: Dummy_vs_Intensity_Comparison\")\n",
    "print(\"\\n\" + comparison_df.to_string(index=False))\n",
    "\n",
    "# Save marginal effects\n",
    "marginal_df = pd.DataFrame(marginal_data)\n",
    "marginal_df.to_excel(OUTPUT_PATH + 'tables/Marginal_Effects_Intensity.xlsx', index=False)\n",
    "marginal_df.to_csv(OUTPUT_PATH + 'tables/Marginal_Effects_Intensity.csv', index=False)\n",
    "\n",
    "print(\"\\nâœ“ Table saved: Marginal_Effects_Intensity\")\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"ðŸ“Š MARGINAL EFFECTS BY INTENSITY LEVEL\")\n",
    "print(\"=\"*100)\n",
    "print(marginal_df.to_string(index=False))\n",
    "\n",
    "# ============================================================================\n",
    "# FINAL SUMMARY\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"âœ… CRISIS INTENSITY MODELS COMPLETE!\")\n",
    "print(\"=\"*100)\n",
    "print(f\"\\nðŸ“ Location: {OUTPUT_PATH}tables/\")\n",
    "print(\"\\nðŸŽ¯ KEY COMPARISON:\")\n",
    "print(f\"   Dummy Specification:\")\n",
    "print(f\"      Î² (REER Ã— Safe Ã— Crisis) = {results4.params['reer_x_safe_x_crisis']:.4f} (p = {results4.pvalues['reer_x_safe_x_crisis']:.4f})\")\n",
    "print(f\"\\n   Intensity Specification:\")\n",
    "print(f\"      Î² (REER Ã— Safe Ã— Intensity) = {results7.params['reer_x_safe_x_intensity']:.4f} (p = {results7.pvalues['reer_x_safe_x_intensity']:.4f})\")\n",
    "print(f\"\\nðŸ’¡ Intensity specification provides:\")\n",
    "print(f\"   â€¢ More variation (continuous vs binary)\")\n",
    "print(f\"   â€¢ Better power to detect effects\")\n",
    "print(f\"   â€¢ Distinguishes mild vs severe crises\")\n",
    "print(\"=\"*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "94fd62ab-4491-4327-af49-cd17c0e2d1cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "ðŸ“Š REGIME ANALYSIS â€“ SOFT INTENSITY THRESHOLD\n",
      "====================================================================================================\n",
      "\n",
      "ðŸ“Š Panel: 2900 obs, 29 countries\n",
      "\n",
      "Regime definition (threshold = 0.5 ):\n",
      "  Regime 0 (Normal/Mild): 2770 obs\n",
      "  Regime 1 (Severe Crisis): 130 obs\n",
      "\n",
      "Creating Table C (soft threshold): REER FE coefficients by regime Ã— group...\n",
      "âœ“ TableC_REER_by_Regime_Group_soft saved.\n",
      "\n",
      "Table C (soft) preview:\n",
      "           Group        Regime    N Beta_REER Std_Error p_value     R2 Within_R2\n",
      "Normal countries   Normal/Mild 2393    0.0458  (0.0898)  0.6102 0.0019    0.0023\n",
      "Normal countries Severe crisis  124   -0.1072  (0.0892)  0.2330 0.0552   -0.0127\n",
      "     Safe havens   Normal/Mild  288   -0.0814  (0.1268)  0.5219 0.0290   -0.0578\n",
      "\n",
      "Creating Figure 1 (soft): Time series with shaded severe regimes...\n",
      "âœ“ Figure1_TimeSeries_Regimes_Shaded_soft saved.\n",
      "\n",
      "Creating Figure 2 (soft): Normal countries scatter by regime...\n",
      "âœ“ Figure2_Normal_REER_vs_Property_Regimes_soft saved.\n",
      "\n",
      "Creating Figure 3 (soft): Safe havens scatter by regime...\n",
      "âœ“ Figure3_SafeHaven_REER_vs_Property_Regimes_soft saved.\n",
      "\n",
      "====================================================================================================\n",
      "âœ… SOFT-THRESHOLD REGIME TABLES & FIGURES COMPLETE\n",
      "====================================================================================================\n",
      "\n",
      "Table:\n",
      "  â€¢ TableC_REER_by_Regime_Group_soft\n",
      "\n",
      "Figures:\n",
      "  â€¢ Figure1_TimeSeries_Regimes_Shaded_soft\n",
      "  â€¢ Figure2_Normal_REER_vs_Property_Regimes_soft\n",
      "  â€¢ Figure3_SafeHaven_REER_vs_Property_Regimes_soft\n",
      "\n",
      "All saved in: C:\\Users\\dirir\\OneDrive\\ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—\\Semester 1\\houses\\house\\workingfile\\\\regime_outputs_soft\\\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from linearmodels.panel import PanelOLS\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# =============================================================================\n",
    "# REGIME ANALYSIS â€“ SOFTER THRESHOLD + CLEAN FIGURES\n",
    "# =============================================================================\n",
    "\n",
    "DATA_PATH = r\"C:\\Users\\dirir\\OneDrive\\ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—\\Semester 1\\houses\\house\\workingfile\\\\\"\n",
    "OUTPUT_PATH = DATA_PATH + \"regime_outputs_soft\\\\\"\n",
    "\n",
    "import os\n",
    "os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
    "os.makedirs(OUTPUT_PATH + \"tables\", exist_ok=True)\n",
    "os.makedirs(OUTPUT_PATH + \"figures\", exist_ok=True)\n",
    "\n",
    "print(\"=\"*100)\n",
    "print(\"ðŸ“Š REGIME ANALYSIS â€“ SOFT INTENSITY THRESHOLD\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 1. LOAD PANEL\n",
    "# -----------------------------------------------------------------------------\n",
    "df = pd.read_csv(DATA_PATH + \"panel_balanced_residential.csv\")\n",
    "\n",
    "SAFE_HAVEN = ['US: United States', 'JP: Japan', 'CH: Switzerland', 'DE: Germany']\n",
    "if 'safe_haven' not in df.columns:\n",
    "    df['safe_haven'] = df['country_code'].isin(SAFE_HAVEN).astype(int)\n",
    "\n",
    "if 'crisis' not in df.columns:\n",
    "    df['crisis'] = 0\n",
    "    df.loc[(df['year'] >= 2008) & (df['year'] <= 2009), 'crisis'] = 1\n",
    "    df.loc[(df['year'] >= 2011) & (df['year'] <= 2012), 'crisis'] = 1\n",
    "    df.loc[(df['year'] >= 2020) & (df['year'] <= 2021), 'crisis'] = 1\n",
    "    df.loc[df['year'] == 2022, 'crisis'] = 1\n",
    "\n",
    "if 'crisis_intensity_std' not in df.columns:\n",
    "    df['crisis_intensity'] = df['reer_volatility'] * df['crisis']\n",
    "    sub = df[df['crisis'] == 1]['crisis_intensity']\n",
    "    std = sub.std()\n",
    "    mean = sub.mean()\n",
    "    if std > 0:\n",
    "        df['crisis_intensity_std'] = (df['crisis_intensity'] - mean) / std\n",
    "    else:\n",
    "        df['crisis_intensity_std'] = df['crisis_intensity']\n",
    "    df.loc[df['crisis'] == 0, 'crisis_intensity_std'] = 0\n",
    "\n",
    "print(\"\\nðŸ“Š Panel:\", len(df), \"obs,\", df['country_code'].nunique(), \"countries\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 2. DEFINE REGIMES WITH SOFTER THRESHOLD (e.g. 0.5)\n",
    "# -----------------------------------------------------------------------------\n",
    "threshold = 0.5\n",
    "df['regime'] = 0\n",
    "df.loc[df['crisis_intensity_std'] > threshold, 'regime'] = 1\n",
    "\n",
    "print(\"\\nRegime definition (threshold =\", threshold, \"):\")\n",
    "print(\"  Regime 0 (Normal/Mild):\", int((df['regime'] == 0).sum()), \"obs\")\n",
    "print(\"  Regime 1 (Severe Crisis):\", int((df['regime'] == 1).sum()), \"obs\")\n",
    "\n",
    "df['time_numeric'] = df['year'] + (df['quarter'] - 1)/4\n",
    "df_panel = df.set_index(['country_code','time_numeric'])\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 3. TABLE C: REER EFFECT BY REGIME Ã— SAFE-HAVEN GROUP\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\nCreating Table C (soft threshold): REER FE coefficients by regime Ã— group...\")\n",
    "\n",
    "def run_group_regime_fe(mask, label_group, label_regime):\n",
    "    sub = df_panel[mask]\n",
    "    sub = sub[['res_price_growth','reer_change_pct',\n",
    "               'reer_volatility','reer_appreciation','res_price_lag1']].dropna()\n",
    "    if len(sub) < 40:\n",
    "        return None\n",
    "    model = PanelOLS(\n",
    "        dependent=sub['res_price_growth'],\n",
    "        exog=sub[['reer_change_pct','reer_volatility',\n",
    "                  'reer_appreciation','res_price_lag1']],\n",
    "        entity_effects=True,\n",
    "        time_effects=True\n",
    "    )\n",
    "    res = model.fit(cov_type='kernel', kernel='bartlett', bandwidth=4)\n",
    "    beta = res.params['reer_change_pct']\n",
    "    se   = res.std_errors['reer_change_pct']\n",
    "    p    = res.pvalues['reer_change_pct']\n",
    "    stars = '***' if p<0.01 else ('**' if p<0.05 else ('*' if p<0.10 else ''))\n",
    "    return {\n",
    "        'Group': label_group,\n",
    "        'Regime': label_regime,\n",
    "        'N': int(res.nobs),\n",
    "        'Beta_REER': f\"{beta:.4f}{stars}\",\n",
    "        'Std_Error': f\"({se:.4f})\",\n",
    "        'p_value': f\"{p:.4f}\",\n",
    "        'R2': f\"{res.rsquared:.4f}\",\n",
    "        'Within_R2': f\"{res.rsquared_within:.4f}\"\n",
    "    }\n",
    "\n",
    "rows_c = []\n",
    "\n",
    "rows_c.append(\n",
    "    run_group_regime_fe(\n",
    "        (df_panel['safe_haven']==0) & (df_panel['regime']==0),\n",
    "        'Normal countries', 'Normal/Mild'\n",
    "    )\n",
    ")\n",
    "rows_c.append(\n",
    "    run_group_regime_fe(\n",
    "        (df_panel['safe_haven']==0) & (df_panel['regime']==1),\n",
    "        'Normal countries', 'Severe crisis'\n",
    "    )\n",
    ")\n",
    "rows_c.append(\n",
    "    run_group_regime_fe(\n",
    "        (df_panel['safe_haven']==1) & (df_panel['regime']==0),\n",
    "        'Safe havens', 'Normal/Mild'\n",
    "    )\n",
    ")\n",
    "rows_c.append(\n",
    "    run_group_regime_fe(\n",
    "        (df_panel['safe_haven']==1) & (df_panel['regime']==1),\n",
    "        'Safe havens', 'Severe crisis'\n",
    "    )\n",
    ")\n",
    "\n",
    "table_c = pd.DataFrame([r for r in rows_c if r is not None])\n",
    "table_c.to_excel(OUTPUT_PATH + \"tables/TableC_REER_by_Regime_Group_soft.xlsx\", index=False)\n",
    "table_c.to_csv(OUTPUT_PATH + \"tables/TableC_REER_by_Regime_Group_soft.csv\", index=False)\n",
    "\n",
    "print(\"âœ“ TableC_REER_by_Regime_Group_soft saved.\")\n",
    "print(\"\\nTable C (soft) preview:\")\n",
    "print(table_c.to_string(index=False))\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 4. FIGURE 1: CLEAN TIME-SERIES WITH SHADED REGIMES\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\nCreating Figure 1 (soft): Time series with shaded severe regimes...\")\n",
    "\n",
    "plt.style.use('default')\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,4))\n",
    "\n",
    "ts = df.groupby('time_numeric')['res_price_growth'].mean().reset_index()\n",
    "ax.plot(ts['time_numeric'], ts['res_price_growth'], color='#2C7BB6', linewidth=2, label='Average property growth')\n",
    "\n",
    "# Shade severe regimes\n",
    "for t, reg in df[['time_numeric','regime']].drop_duplicates().values:\n",
    "    if reg == 1:\n",
    "        ax.axvspan(t-0.125, t+0.125, color='#D7191C', alpha=0.12)\n",
    "\n",
    "ax.axhline(0, color='black', linewidth=1, alpha=0.5)\n",
    "ax.set_xlabel(\"Year\")\n",
    "ax.set_ylabel(\"Avg Property Price Growth (%)\")\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_PATH + \"figures/Figure1_TimeSeries_Regimes_Shaded_soft.png\", dpi=300)\n",
    "plt.savefig(OUTPUT_PATH + \"figures/Figure1_TimeSeries_Regimes_Shaded_soft.pdf\")\n",
    "plt.close()\n",
    "\n",
    "print(\"âœ“ Figure1_TimeSeries_Regimes_Shaded_soft saved.\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 5. FIGURE 2: NORMAL COUNTRIES â€“ 1Ã—2 SCATTER BY REGIME\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\nCreating Figure 2 (soft): Normal countries scatter by regime...\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12,5), sharex=True, sharey=True)\n",
    "\n",
    "configs_norm = [\n",
    "    ((df['safe_haven']==0) & (df['regime']==0), \"Normal â€“ Normal/Mild\", 0),\n",
    "    ((df['safe_haven']==0) & (df['regime']==1), \"Normal â€“ Severe crisis\", 1),\n",
    "]\n",
    "\n",
    "for mask, title, j in configs_norm:\n",
    "    sub = df[mask].dropna(subset=['reer_change_pct','res_price_growth'])\n",
    "    ax = axes[j]\n",
    "    sns.regplot(\n",
    "        data=sub,\n",
    "        x='reer_change_pct',\n",
    "        y='res_price_growth',\n",
    "        scatter_kws={'alpha':0.3, 's':20},\n",
    "        line_kws={'color':'black','linewidth':2},\n",
    "        ax=ax\n",
    "    )\n",
    "    ax.set_title(title)\n",
    "    ax.axhline(0, color='grey', linewidth=1, alpha=0.5)\n",
    "    ax.axvline(0, color='grey', linewidth=1, alpha=0.5)\n",
    "\n",
    "fig.text(0.5, 0.02, 'REER Change (%)', ha='center')\n",
    "fig.text(0.04, 0.5, 'Property Price Growth (%)', va='center', rotation='vertical')\n",
    "plt.tight_layout(rect=[0.05, 0.05, 1, 0.95])\n",
    "plt.savefig(OUTPUT_PATH + \"figures/Figure2_Normal_REER_vs_Property_Regimes_soft.png\", dpi=300)\n",
    "plt.savefig(OUTPUT_PATH + \"figures/Figure2_Normal_REER_vs_Property_Regimes_soft.pdf\")\n",
    "plt.close()\n",
    "\n",
    "print(\"âœ“ Figure2_Normal_REER_vs_Property_Regimes_soft saved.\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 6. FIGURE 3: SAFE HAVENS â€“ 1Ã—2 SCATTER BY REGIME (WITH CHECK)\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\nCreating Figure 3 (soft): Safe havens scatter by regime...\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12,5), sharex=True, sharey=True)\n",
    "\n",
    "configs_safe = [\n",
    "    ((df['safe_haven']==1) & (df['regime']==0), \"Safe havens â€“ Normal/Mild\", 0),\n",
    "    ((df['safe_haven']==1) & (df['regime']==1), \"Safe havens â€“ Severe crisis\", 1),\n",
    "]\n",
    "\n",
    "for mask, title, j in configs_safe:\n",
    "    sub = df[mask].dropna(subset=['reer_change_pct','res_price_growth'])\n",
    "    ax = axes[j]\n",
    "    if len(sub) < 10:\n",
    "        ax.text(0.5, 0.5, \"Too few observations\", ha='center', va='center', fontsize=10)\n",
    "        ax.set_title(title)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        continue\n",
    "    sns.regplot(\n",
    "        data=sub,\n",
    "        x='reer_change_pct',\n",
    "        y='res_price_growth',\n",
    "        scatter_kws={'alpha':0.3, 's':20},\n",
    "        line_kws={'color':'black','linewidth':2},\n",
    "        ax=ax\n",
    "    )\n",
    "    ax.set_title(title)\n",
    "    ax.axhline(0, color='grey', linewidth=1, alpha=0.5)\n",
    "    ax.axvline(0, color='grey', linewidth=1, alpha=0.5)\n",
    "\n",
    "fig.text(0.5, 0.02, 'REER Change (%)', ha='center')\n",
    "fig.text(0.04, 0.5, 'Property Price Growth (%)', va='center', rotation='vertical')\n",
    "plt.tight_layout(rect=[0.05, 0.05, 1, 0.95])\n",
    "plt.savefig(OUTPUT_PATH + \"figures/Figure3_SafeHaven_REER_vs_Property_Regimes_soft.png\", dpi=300)\n",
    "plt.savefig(OUTPUT_PATH + \"figures/Figure3_SafeHaven_REER_vs_Property_Regimes_soft.pdf\")\n",
    "plt.close()\n",
    "\n",
    "print(\"âœ“ Figure3_SafeHaven_REER_vs_Property_Regimes_soft saved.\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 7. SUMMARY\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"âœ… SOFT-THRESHOLD REGIME TABLES & FIGURES COMPLETE\")\n",
    "print(\"=\"*100)\n",
    "print(\"\\nTable:\")\n",
    "print(\"  â€¢ TableC_REER_by_Regime_Group_soft\")\n",
    "print(\"\\nFigures:\")\n",
    "print(\"  â€¢ Figure1_TimeSeries_Regimes_Shaded_soft\")\n",
    "print(\"  â€¢ Figure2_Normal_REER_vs_Property_Regimes_soft\")\n",
    "print(\"  â€¢ Figure3_SafeHaven_REER_vs_Property_Regimes_soft\")\n",
    "print(\"\\nAll saved in:\", OUTPUT_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6bdea313-51d8-45aa-810b-9f26b7b91c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: C:\\Users\\dirir\\OneDrive\\ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—\\Semester 1\\houses\\house\\workingfile\\\\dy_connectedness_input.csv\n",
      "        date    fx_chf    fx_usd  house_return   fx_norm\n",
      "0 2000-06-30  2.535111  2.060495      2.102753 -0.460590\n",
      "1 2000-09-30 -1.369704  1.760318      1.443012 -1.511141\n",
      "2 2000-12-31  2.636225  0.948006      1.110501  1.486406\n",
      "3 2001-03-31 -0.481596  2.904444      1.254788  0.705674\n",
      "4 2001-06-30 -1.394170  1.335968      1.385210 -0.131287\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "DATA_PATH = r\"C:\\Users\\dirir\\OneDrive\\ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—\\Semester 1\\houses\\house\\workingfile\\\\\"\n",
    "\n",
    "# 1. Load your balanced panel\n",
    "df = pd.read_csv(DATA_PATH + \"panel_balanced_residential.csv\")\n",
    "\n",
    "# 2. Pick variables for connectedness (example: CHF, JPY, USD vs housing)\n",
    "# You must adjust country_code labels to match your file exactly\n",
    "safe_fx = ['CH: Switzerland', 'JP: Japan', 'US: United States']\n",
    "\n",
    "# Filter to those currencies\n",
    "sub = df[df['country_code'].isin(safe_fx)].copy()\n",
    "\n",
    "# 3. Build a 'date' variable (quarterly)\n",
    "sub['date'] = pd.PeriodIndex(year=sub['year'], quarter=sub['quarter']).to_timestamp('Q')\n",
    "\n",
    "# 4. Compute FX returns (REER change) and housing returns per country\n",
    "sub = sub.sort_values(['country_code','date'])\n",
    "\n",
    "sub['fx_return'] = sub.groupby('country_code')['reer_broad'].pct_change() * 100\n",
    "sub['house_return'] = sub.groupby('country_code')['residential_price'].pct_change() * 100\n",
    "\n",
    "# 5. Pivot to wide format: one column per FX, one common housing index (mean across all)\n",
    "fx_wide = sub.pivot(index='date', columns='country_code', values='fx_return')\n",
    "fx_wide.columns = ['fx_chf' if 'Switzerland' in c else\n",
    "                   'fx_jpy' if 'Japan' in c else\n",
    "                   'fx_usd' for c in fx_wide.columns]\n",
    "\n",
    "# Housing: average across all three safe havens (you can change this)\n",
    "house_series = (sub.groupby('date')['house_return']\n",
    "                  .mean()\n",
    "                  .rename('house_return'))\n",
    "\n",
    "# 6. Combine into df_fx_house and drop missing rows\n",
    "df_fx_house = pd.concat([fx_wide, house_series], axis=1).dropna().reset_index()\n",
    "\n",
    "# Optional: construct a simple non-safe FX index as average of others\n",
    "non_safe = df[~df['country_code'].isin(safe_fx)].copy()\n",
    "non_safe['date'] = pd.PeriodIndex(year=non_safe['year'], quarter=non_safe['quarter']).to_timestamp('Q')\n",
    "non_safe = non_safe.sort_values(['country_code','date'])\n",
    "non_safe['fx_return'] = non_safe.groupby('country_code')['reer_broad'].pct_change() * 100\n",
    "fx_norm = (non_safe.groupby('date')['fx_return']\n",
    "                   .mean()\n",
    "                   .rename('fx_norm'))\n",
    "df_fx_house = pd.merge(df_fx_house, fx_norm, on='date', how='left').dropna()\n",
    "\n",
    "# 7. Save for R\n",
    "df_fx_house.to_csv(\n",
    "    DATA_PATH + \"dy_connectedness_input.csv\",\n",
    "    index=False\n",
    ")\n",
    "\n",
    "print(\"Saved:\", DATA_PATH + \"dy_connectedness_input.csv\")\n",
    "print(df_fx_house.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f5ad26ae-a762-4c06-85bc-2c243d64ef1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        date   fx_safe   fx_norm  house_return\n",
      "0 2000-06-30  2.297803 -0.460590      2.102753\n",
      "1 2000-09-30  0.195307 -1.511141      1.443012\n",
      "2 2000-12-31  1.792115  1.486406      1.110501\n",
      "3 2001-03-31  1.211424  0.705674      1.254788\n",
      "4 2001-06-30 -0.029101 -0.131287      1.385210\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "DATA_PATH = r\"C:\\Users\\dirir\\OneDrive\\ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—\\Semester 1\\houses\\house\\workingfile\\\\\"\n",
    "\n",
    "df = pd.read_csv(DATA_PATH + \"panel_balanced_residential.csv\")\n",
    "\n",
    "# 1. Create quarterly date\n",
    "df['date'] = pd.PeriodIndex(year=df['year'], quarter=df['quarter']).to_timestamp('Q')\n",
    "\n",
    "# 2. Safe havens\n",
    "safe_fx = ['CH: Switzerland', 'US: United States']  # keep it simple for now\n",
    "\n",
    "sub_safe = df[df['country_code'].isin(safe_fx)].copy()\n",
    "sub_safe = sub_safe.sort_values(['country_code','date'])\n",
    "\n",
    "sub_safe['fx_return'] = sub_safe.groupby('country_code')['reer_broad'].pct_change() * 100\n",
    "sub_safe['house_return'] = sub_safe.groupby('country_code')['residential_price'].pct_change() * 100\n",
    "\n",
    "# Pivot to one row per date with mean across safe havens\n",
    "fx_safe = (sub_safe.pivot_table(index='date',\n",
    "                                values='fx_return',\n",
    "                                aggfunc='mean')\n",
    "                    .rename(columns={'fx_return':'fx_safe'}))\n",
    "\n",
    "house = (sub_safe.groupby('date')['house_return']\n",
    "                  .mean()\n",
    "                  .rename('house_return'))\n",
    "\n",
    "# 3. Non-safe FX index\n",
    "non_safe = df[~df['country_code'].isin(safe_fx)].copy()\n",
    "non_safe = non_safe.sort_values(['country_code','date'])\n",
    "non_safe['fx_return'] = non_safe.groupby('country_code')['reer_broad'].pct_change() * 100\n",
    "\n",
    "fx_norm = (non_safe.groupby('date')['fx_return']\n",
    "                   .mean()\n",
    "                   .rename('fx_norm'))\n",
    "\n",
    "# 4. Merge to ONE DATAFRAME with UNIQUE dates\n",
    "df_fx_house = pd.concat([fx_safe, fx_norm, house], axis=1).dropna().reset_index()\n",
    "\n",
    "# Sanity check: dates must be unique\n",
    "assert not df_fx_house['date'].duplicated().any()\n",
    "\n",
    "df_fx_house.to_csv(DATA_PATH + \"dy_connectedness_input.csv\", index=False)\n",
    "print(df_fx_house.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "26f35827-c123-44ba-b975-6dde03fec595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date   fx_safe   fx_norm  house_return\n",
      "0  2000-06-30  2.297803 -0.460590      2.102753\n",
      "1  2000-09-30  0.195307 -1.511141      1.443012\n",
      "2  2000-12-31  1.792115  1.486406      1.110501\n",
      "3  2001-03-31  1.211424  0.705674      1.254788\n",
      "4  2001-06-30 -0.029101 -0.131287      1.385210\n",
      "Rows: 99\n",
      "Unique dates: 99\n",
      "First duplicated dates:\n",
      "Series([], Name: date, dtype: object)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "DATA_PATH = r\"C:\\Users\\dirir\\OneDrive\\ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—\\Semester 1\\houses\\house\\workingfile\\\\\"\n",
    "df = pd.read_csv(DATA_PATH + \"dy_connectedness_input.csv\")\n",
    "\n",
    "print(df.head())\n",
    "print(\"Rows:\", len(df))\n",
    "print(\"Unique dates:\", df['date'].nunique())\n",
    "print(\"First duplicated dates:\")\n",
    "print(df[df['date'].duplicated()]['date'].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6ddae0-c9cd-4893-8530-0e5966005f41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
